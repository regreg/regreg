{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some common loss functions\n",
    "\n",
    "There are several commonly used smooth loss functions built into\n",
    "`regreg`:\n",
    "\n",
    "* squared error loss (`regreg.api.squared_error`)\n",
    "\n",
    "* Logistic loss (`regreg.glm.glm.logistic`)\n",
    "\n",
    "* Poisson loss (`regreg.glm.glm.poisson`)\n",
    "\n",
    "* Cox proportional hazards (`regreg.glm.glm.coxph`, depends on\n",
    "  `statsmodels`)\n",
    "\n",
    "* Huber loss (`regreg.glm.glm.huber`)\n",
    "\n",
    "* Huberized SVM (`regreg.smooth.losses.huberized_svm`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$$\\ell^{\\text{logit}}\\left(X_{}\\beta\\right)$$"
      ],
      "text/plain": [
       "<regreg.smooth.glm.glm at 0x120a8bbe0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import regreg.api as rr\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import rpy2.robjects as rpy2\n",
    "from rpy2.robjects import numpy2ri\n",
    "numpy2ri.activate()\n",
    "\n",
    "X = np.random.standard_normal((100, 5))\n",
    "X *= np.linspace(1, 3, 5)[None, :]\n",
    "Y = np.random.binomial(1, 0.5, (100,))\n",
    "loss = rr.glm.logistic(X, Y)\n",
    "loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\ell^{\\text{logit}}\\left(X_{}\\beta\\right)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.03772602, -0.04863572, -0.08215854, -0.07378244,  0.04341304,\n",
       "       -0.18794823])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rpy2.r.assign('X', X)\n",
    "rpy2.r.assign('Y', Y)\n",
    "r_soln = rpy2.r('glm(Y ~ X, family=binomial)$coef')\n",
    "loss.solve()\n",
    "np.array(r_soln)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The losses can very easily be combined with a penalty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.        , -0.03926608, -0.05179897,  0.03680599, -0.1725902 ])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "penalty = rr.l1norm(5, lagrange=2)\n",
    "problem = rr.simple_problem(loss, penalty)\n",
    "problem.solve(tol=1.e-12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "R[write to console]: Loading required package: Matrix\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "R[write to console]: Loading required package: foreach\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "R[write to console]: Loaded glmnet 2.0-18\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 x 1 sparse Matrix of class \"dgCMatrix\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           1"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "(Intercept)"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  .         "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "V1         "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  .         "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "V2         "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -0.03926385"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "V3         "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -0.05179873"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "V4         "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.03680646"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "V5         "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -0.17259009"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "R object with classes: ('dgCMatrix',) mapped to:"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rpy2.r('''\n",
    "library(glmnet)\n",
    "Y = as.numeric(Y)\n",
    "G = glmnet(X, Y, intercept=FALSE, standardize=FALSE, family='binomial')\n",
    "print(coef(G, s=2 / nrow(X), x=X, y=Y, exact=TRUE))\n",
    "''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose we want to match `glmnet` exactly without having to specify\n",
    "`intercept=FALSE` and `standardize=FALSE`. The `normalize`\n",
    "transformation can be used here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.03968882, -0.        , -0.04130455, -0.05131366,  0.03490101,\n",
       "       -0.17476366])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = X.shape[0]\n",
    "X_intercept = np.hstack([np.ones((X.shape[0], 1)), X])\n",
    "X_normalized = rr.normalize(X_intercept, intercept_column=0, scale=False)\n",
    "loss_normalized = rr.glm.logistic(X_normalized, Y)\n",
    "penalty_normalized = rr.weighted_l1norm([0] + [1]*5, lagrange=2.)\n",
    "problem_normalized = rr.simple_problem(loss_normalized, penalty_normalized)\n",
    "coefR = problem_normalized.solve(tol=1.e-12, min_its=200)\n",
    "coefR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "coefG = np.array(rpy2.r('as.numeric(coef(G, s=2 / nrow(X), exact=TRUE, x=X, y=Y))'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(65.90584223689014, 65.8867255949289)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "problem_normalized.objective(coefG), problem_normalized.objective(coefR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In theory, using the `standardize=TRUE` option in `glmnet` should be\n",
    "the same as using `scale=True, value=np.sqrt((n-1)/n)` in\n",
    "`normalize`, though the results don’t match without some adjustment.\n",
    "This is because `glmnet` returns coefficients that are on the scale of\n",
    "the original $X$.\n",
    "\n",
    "Dividing `regreg`’s coefficients by the `col_stds` corrects this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.04022662, -0.        , -0.02318002, -0.02853925,  0.01882133,\n",
       "       -0.15450194])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_intercept = np.hstack([np.ones((X.shape[0], 1)), X])\n",
    "X_normalized = rr.normalize(X_intercept, intercept_column=0,\n",
    "                           value=np.sqrt((n-1.)/n))\n",
    "loss_normalized = rr.glm.logistic(X_normalized, Y)\n",
    "penalty_normalized = rr.weighted_l1norm([0] + [1]*5, lagrange=2.)\n",
    "problem_normalized = rr.simple_problem(loss_normalized, penalty_normalized)\n",
    "coefR = problem_normalized.solve(min_its=300)\n",
    "coefR / X_normalized.col_stds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "rpy2.r('''\n",
    "Y = as.numeric(Y)\n",
    "G = glmnet(X, Y, standardize=TRUE, intercept=TRUE, family='binomial')\n",
    "coefG = as.numeric(coef(G, s=2 / nrow(X), exact=TRUE, x=X, y=Y))\n",
    "''')\n",
    "coefG = np.array(rpy2.r('coefG'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(67.64597880430388, 67.6396650718625)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coefG = coefG * X_normalized.col_stds\n",
    "problem_normalized.objective(coefG), problem_normalized.objective(coefR)\n",
    "(67.64597880430388, 67.639665071862495)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining a new smooth function\n",
    "\n",
    "A smooth function only really needs a `smooth_objective` method in\n",
    "order to be used in `regreg`.\n",
    "\n",
    "For example, suppose we want to define the loss\n",
    "\n",
    "$$\n",
    "\\mu \\mapsto \\frac{1}{2} \\|\\mu\\|^2_2  - \\sum_{i=1}^k \\log(b_i - a_i^T\\mu)\n",
    "$$\n",
    "\n",
    "as a smooth approximation to the function\n",
    "\n",
    "$$\n",
    "  \\mu \\mapsto \\frac{1}{2} \\|\\mu\\|^2_2 + I^{\\infty}_K(\\mu)\n",
    "\n",
    "where :math:`I^{\\infty}_K` is the indicator of\n",
    "$$\n",
    "\n",
    "$K=\\left\\{\\mu: a_i^T\\mu\\leq b_i, 1 \\leq i \\leq k\\right\\}$ (i.e. 0\n",
    "inside $K$ and $\\infty$ outside $K$)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class barrier(rr.smooth_atom):\n",
    "\n",
    "    # the argumenets [coef, offset, quadratic, initial]\n",
    "    # are passed when a function is composed with a linear_transform\n",
    "\n",
    "    objective_template = r\"\"\"\\ell^{\\text{barrier}}\\left(%(var)s\\right)\\\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 shape,\n",
    "                 A,\n",
    "                 b,\n",
    "                 coef=1.,\n",
    "                 offset=None,\n",
    "                 quadratic=None,\n",
    "                 initial=None):\n",
    "        rr.smooth_atom.__init__(self,\n",
    "                                shape,\n",
    "                                coef=coef,\n",
    "                                offset=offset,\n",
    "                                quadratic=quadratic,\n",
    "                                initial=initial)\n",
    "        self.A = A\n",
    "        self.b = b\n",
    "\n",
    "    def smooth_objective(self, mean_param, mode='both', check_feasibility=False):\n",
    "        mean_param = self.apply_offset(mean_param)\n",
    "        slack = self.b - self.A.dot(mean_param)\n",
    "        if mode == 'both':\n",
    "            f = self.scale(np.sum(mean_param**2/2.) - np.log(slack).sum())\n",
    "            g = self.scale(mean_param + self.A.T.dot(1. / slack))\n",
    "            return f, g\n",
    "        elif mode == 'grad':\n",
    "            g = self.scale(mean_param + self.A.T.dot(1. / slack))\n",
    "            return g\n",
    "        elif mode == 'func':\n",
    "            f = self.scale(np.sum(mean_param**2/2.) - np.log(slack).sum())\n",
    "            return f\n",
    "        else:\n",
    "            return ValueError('mode incorrectly specified')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$$\\ell^{\\text{barrier}}\\left(\\beta\\right)    $$"
      ],
      "text/plain": [
       "<__main__.barrier at 0x12136b208>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = np.array([[1, 0.], [1, 1]])\n",
    "b = np.array([3., 4])\n",
    "barrier_loss = barrier((2,), A, b)\n",
    "barrier_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\ell^{\\text{barrier}}\\left(\\beta\\right)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.49815853, -0.21229384])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "barrier_loss.solve(min_its=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The loss can now be combined with a penalty or constraint very easily."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.39719293, -0.10280707])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l1_bound = rr.l1norm(2, bound=0.5)\n",
    "problem = rr.simple_problem(barrier_loss, l1_bound)\n",
    "problem.solve()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The loss can also be composed with a linear transform:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$$\\ell^{\\text{barrier}}\\left(X_{}\\beta\\right)    $$"
      ],
      "text/plain": [
       "affine_smooth(<__main__.barrier object at 0x12136b208>, <regreg.affine.linear_transform object at 0x12136b2b0>, store_grad=True)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.random.standard_normal((2,1))\n",
    "lossX = rr.affine_smooth(barrier_loss, X)\n",
    "lossX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\ell^{\\text{barrier}}\\left(X_{}\\beta\\right)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.34741628])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lossX.solve()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Huberized lasso\n",
    "\n",
    "The Huberized lasso minimizes the following objective\n",
    "\n",
    "$$\n",
    "H_{\\delta}(Y - X\\beta) + \\lambda \\|\\beta\\|_1\n",
    "$$\n",
    "\n",
    "where $H_{\\delta}(\\cdot)$ is a function applied element-wise,\n",
    "\n",
    "$$\n",
    " H_{\\delta}(r) = \\left\\{\\begin{array}{ll} r^2/2 & \\mbox{ if } |r| \\leq\n",
    "\\delta \\\\ \\delta r - \\delta^2/2 & \\mbox{ else}\\end{array} \\right.\n",
    "$$\n",
    "\n",
    "Let’s look at the Huber loss for a smoothing parameter of\n",
    "$\\delta=1.2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1215210f0>]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q = rr.identity_quadratic(1.2, 0., 0., 0.)\n",
    "loss = rr.l1norm(1, lagrange=1).smoothed(q)\n",
    "xval = np.linspace(-2,2,101)\n",
    "yval = [loss.smooth_objective(x, 'func') for x in xval]\n",
    "huber_fig = plt.figure(figsize=(8,8))\n",
    "huber_ax = huber_fig.gca()\n",
    "huber_ax.plot(xval, yval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Huber loss is built into regreg, but can also be obtained by\n",
    "smoothing the `l1norm` atom. We will verify the two methods yield the\n",
    "same solutions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.random.standard_normal((50, 10))\n",
    "Y = np.random.standard_normal(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "penalty = rr.l1norm(10,lagrange=5.)\n",
    "loss_atom = rr.l1norm.affine(X, -Y, lagrange=1.).smoothed(rr.identity_quadratic(0.5,0,0,0))\n",
    "loss = rr.glm.huber(X, Y, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.          0.          0.          0.00819026 -0.07042976  0.\n",
      " -0.         -0.07866935 -0.12959658  0.0055762 ]\n"
     ]
    }
   ],
   "source": [
    "problem1 = rr.simple_problem(loss_atom, penalty)\n",
    "print(problem1.solve(tol=1.e-12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.          0.          0.          0.00819044 -0.07042971  0.\n",
      " -0.         -0.07866952 -0.12959655  0.00557598]\n"
     ]
    }
   ],
   "source": [
    "problem2 = rr.simple_problem(loss, penalty)\n",
    "print(problem2.solve(tol=1.e-12))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Poisson regression tutorial\n",
    "\n",
    "The Poisson regression problem minimizes the objective\n",
    "\n",
    "$$\n",
    "-2 \\left(Y^TX\\beta - \\sum_{i=1}^n \\mbox{exp}(x_i^T\\beta) \\right), \\qquad Y_i \\in {0,1,2,\\ldots}\n",
    "$$\n",
    "\n",
    "which corresponds to the usual Poisson regression model\n",
    "\n",
    "$$\n",
    "P(Y=y|X=x) = \\frac{\\mbox{exp}(y \\cdot x^T\\beta-\\mbox{exp}(x^T\\beta))}{y!}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 100\n",
    "p = 5\n",
    "X = np.random.standard_normal((n,p))\n",
    "Y = np.random.randint(0,100,n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can create the problem object, beginning with the loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jonathantaylor/git-repos/regreg/regreg/smooth/glm.py:840: RuntimeWarning: divide by zero encountered in log\n",
      "  loss_terms = - coef * ((counts - 1) * np.log(counts))\n",
      "/Users/jonathantaylor/git-repos/regreg/regreg/smooth/glm.py:887: RuntimeWarning: overflow encountered in exp\n",
      "  exp_x = np.exp(x)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-0.2470568 , -1.10732254,  0.59664194,  0.82564975, -1.45966645])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = rr.glm.poisson(X, Y)\n",
    "loss.solve()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.24552094, -1.10726199,  0.59542001,  0.82873657, -1.45483286])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rpy2.r.assign('Y', Y)\n",
    "rpy2.r.assign('X', X)\n",
    "np.array(rpy2.r('coef(glm(Y ~ X - 1, family=poisson()))'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic regression with a ridge penalty\n",
    "\n",
    "In `regreg`, ridge penalties can be specified by the `quadratic`\n",
    "attribute of a loss (or a penalty).\n",
    "\n",
    "The regularized ridge logistic regression problem minimizes the\n",
    "objective\n",
    "\n",
    "$$\n",
    "-2\\left(Y^TX\\beta - \\sum_i \\log \\left[ 1 + \\exp(x_i^T\\beta) \\right] \\right) + \\lambda \\|\\beta\\|_2^2\n",
    "$$\n",
    "\n",
    "which corresponds to the usual logistic regression model\n",
    "\n",
    "$$\n",
    "P(Y=1|X=x) = \\mbox{logit}(x^T\\beta) = \\frac{1}{1 + \\mbox{exp}(-x^T\\beta)}\n",
    "$$\n",
    "\n",
    "Let’s generate some sample data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.random.standard_normal((200, 10))\n",
    "Y = np.random.randint(0,2,200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can create the problem object, beginning with the loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$$\\ell^{\\text{logit}}\\left(X_{}\\beta\\right)$$"
      ],
      "text/plain": [
       "<regreg.smooth.glm.glm at 0x12173e208>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = rr.glm.logistic(X, Y)\n",
    "penalty = rr.identity_quadratic(1., 0., 0., 0.)\n",
    "loss.quadratic = penalty\n",
    "loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\ell^{\\text{logit}}\\left(X_{}\\beta\\right)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "penalty.coef\n",
    "1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.20900315,  0.11839588, -0.1813296 ,  0.14529937, -0.10693407,\n",
       "        0.07222367,  0.28326734,  0.051914  ,  0.05141479, -0.1229806 ])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss.solve()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.14636856,  0.08683651, -0.12888217,  0.09303803, -0.07941929,\n",
       "        0.04877304,  0.21071889,  0.03228041,  0.0328905 , -0.08097988])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "penalty.coef = 20.\n",
    "loss.solve()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multinomial regression\n",
    "\n",
    "The multinomial regression problem minimizes the objective\n",
    "\n",
    "$$\n",
    "-\\left[ \\sum_{j=1}^{J-1} \\sum_{k=1}^p \\beta_{jk}\\sum_{i=1}^n x_{ik}y_{ij}\n",
    " - \\sum_{i=1}^n \\log \\left(1 + \\mbox{exp}(x_i^T\\beta_j) \\right)\\right]\n",
    "$$\n",
    "\n",
    "which corresponds to a baseline category logit model for $J$\n",
    "nominal categories (e.g. Agresti, p.g. 272). For $i \\ne J$ the\n",
    "probabilities are measured relative to a baseline category $J$\n",
    "\n",
    "$$\n",
    "\\frac{P(\\mbox{Category } i)}{P(\\mbox{Category } J)} = \\mbox{logit}(x^T\\beta_i) = \\frac{1}{1 + \\mbox{exp}(-x^T\\beta_i)}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from regreg.smooth.glm import multinomial_loglike"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The only code needed to add multinomial regression to RegReg is a class\n",
    "with one method which computes the objective and its gradient.\n",
    "\n",
    "Next, let’s generate some example data. The multinomial counts will be\n",
    "stored in a $n \\times J$ array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "J = 5\n",
    "n = 500\n",
    "p = 10\n",
    "X = np.random.standard_normal((n,p))\n",
    "Y = np.random.randint(0,10,n*J).reshape((n,J))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can create the problem object, beginning with the loss function.\n",
    "The coefficients will be stored in a $p \\times (J-1)$ array, and\n",
    "we need to let RegReg know that the coefficients will be a 2d array\n",
    "instead of a vector. We can do this by defining the input_shape in a\n",
    "linear_transform object that multiplies by X,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jonathantaylor/git-repos/regreg/regreg/smooth/glm.py:1114: RuntimeWarning: divide by zero encountered in log\n",
      "  loss_terms = np.log(saturated) * self.counts\n",
      "/Users/jonathantaylor/git-repos/regreg/regreg/smooth/glm.py:1114: RuntimeWarning: invalid value encountered in multiply\n",
      "  loss_terms = np.log(saturated) * self.counts\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(10, 4)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multX = rr.linear_transform(X, input_shape=(p,J-1))\n",
    "loss = rr.multinomial_loglike.linear(multX, counts=Y)\n",
    "loss.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we can solve the problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.0548204 ,  0.02639891,  0.06349326,  0.05484217],\n",
       "       [-0.00801381, -0.05425095, -0.00092391,  0.01554628],\n",
       "       [ 0.02863027,  0.04296675,  0.01209194, -0.00340814],\n",
       "       [-0.00482727, -0.04333662, -0.01714575, -0.02382563],\n",
       "       [ 0.04011513,  0.05115482,  0.02824501,  0.02031728],\n",
       "       [ 0.02297367,  0.02673593,  0.06309896,  0.04316998],\n",
       "       [ 0.03164772,  0.03662476, -0.01244323,  0.01106618],\n",
       "       [ 0.01161456,  0.03501517, -0.00586908, -0.01117148],\n",
       "       [ 0.004103  ,  0.01089722,  0.02079106,  0.02713465],\n",
       "       [-0.01233972,  0.03607589,  0.02923168, -0.04108609]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss.solve()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When $J=2$ this model should reduce to logistic regression. We can\n",
    "easily check that this is the case by first fitting the multinomial\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jonathantaylor/git-repos/regreg/regreg/smooth/glm.py:1113: RuntimeWarning: invalid value encountered in true_divide\n",
      "  saturated = self.counts / (1. * self.trials[:,np.newaxis])\n",
      "/Users/jonathantaylor/git-repos/regreg/regreg/smooth/glm.py:1114: RuntimeWarning: divide by zero encountered in log\n",
      "  loss_terms = np.log(saturated) * self.counts\n",
      "/Users/jonathantaylor/git-repos/regreg/regreg/smooth/glm.py:1114: RuntimeWarning: invalid value encountered in multiply\n",
      "  loss_terms = np.log(saturated) * self.counts\n"
     ]
    }
   ],
   "source": [
    "J = 2\n",
    "Y = np.random.randint(0,10,n*J).reshape((n,J))\n",
    "multX = rr.linear_transform(X, input_shape=(p,J-1))\n",
    "loss = rr.multinomial_loglike.linear(multX, counts=Y)\n",
    "solver = rr.FISTA(loss)\n",
    "solver.fit(tol=1e-6)\n",
    "multinomial_coefs = solver.composite.coefs.flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the equivalent logistic regresison model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jonathantaylor/git-repos/regreg/regreg/smooth/glm.py:615: RuntimeWarning: invalid value encountered in true_divide\n",
      "  saturated = self.successes / self.trials\n"
     ]
    }
   ],
   "source": [
    "successes = Y[:,0]\n",
    "trials = np.sum(Y, axis=1)\n",
    "loss = rr.glm.logistic(X, successes, trials=trials)\n",
    "solver = rr.FISTA(loss)\n",
    "solver.fit(tol=1e-6)\n",
    "logistic_coefs = solver.composite.coefs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we can check that the two models gave the same coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.9565979769201473e-16\n"
     ]
    }
   ],
   "source": [
    "print(np.linalg.norm(multinomial_coefs - logistic_coefs) / np.linalg.norm(logistic_coefs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hinge loss\n",
    "\n",
    "The SVM can be parametrized various ways, one way to write it as a\n",
    "regression problem is to use the hinge loss:\n",
    "\n",
    "$$\n",
    "\\ell(r) = \\max(1-x, 0)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1217762b0>]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hinge = lambda x: np.maximum(1-x, 0)\n",
    "fig = plt.figure(figsize=(9,6))\n",
    "ax = fig.gca()\n",
    "r = np.linspace(-1,2,100)\n",
    "ax.plot(r, hinge(r))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The SVM loss is then\n",
    "\n",
    "$$\n",
    "\\ell(\\beta) = C \\sum_{i=1}^n h(Y_i X_i^T\\beta) + \\frac{1}{2} \\|\\beta\\|^2_2\n",
    "$$\n",
    "\n",
    "where $Y_i \\in \\{-1,1\\}$ and $X_i \\in \\mathbb{R}^p$ is one\n",
    "of the feature vectors.\n",
    "\n",
    "In regreg, the hinge loss can be represented by composition of some of\n",
    "the basic atoms. Specifcally, let\n",
    "$g:\\mathbb{R}^n \\rightarrow \\mathbb{R}$ be the sum of positive\n",
    "part function\n",
    "\n",
    "$$\n",
    "g(z) = \\sum_{i=1}^n\\max(z_i, 0).\n",
    "$$\n",
    "\n",
    "Then,\n",
    "\n",
    "$$\n",
    "  \\ell(\\beta) = g\\left(Y \\cdot X\\beta \\right)\n",
    "\n",
    "where the product in the parentheses is elementwise multiplication.\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$$\\lambda_{} \\left(\\sum_{i=1}^{p} (X_{}\\beta - \\alpha_{})_i^+\\right)$$"
      ],
      "text/plain": [
       "affine_atom(positive_part((1,), lagrange=1.000000, offset=array([-1.])), array([[-1.]]))"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_part = np.array([[-1.]])\n",
    "offset = np.array([1.])\n",
    "hinge_rep = rr.positive_part.affine(linear_part, offset, lagrange=1.)\n",
    "hinge_rep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\lambda_{} \\left(\\sum_{i=1}^{p} (X_{}\\beta - \\alpha_{})_i^+\\right)\n",
    "$$\n",
    "\n",
    "Let’s plot the loss to be sure it agrees with our original hinge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiEAAAFlCAYAAAA9NjhgAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nCHMTV8TjAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 648x432 with 1 Axes>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ax.plot(r, [hinge_rep.nonsmooth_objective(v) for v in r])\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a vectorized version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 1000\n",
    "P = 200\n",
    "Y = 2 * np.random.binomial(1, 0.5, size=(N,)) - 1.\n",
    "X = np.random.standard_normal((N,P))\n",
    "#X[Y==1] += np.array([30,-20] + (P-2)*[0])[np.newaxis,:]\n",
    "X -= X.mean(0)[np.newaxis, :]\n",
    "hinge_vec = rr.positive_part.affine(-Y[:, None] * X, np.ones_like(Y), lagrange=1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6813.323424537586, 6813.323424537586)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beta = np.ones(X.shape[1])\n",
    "hinge_vec.nonsmooth_objective(beta), np.maximum(1 - Y * X.dot(beta), 0).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Smoothed hinge\n",
    "\n",
    "For optimization, the hinge loss is not differentiable so it is often\n",
    "smoothed first.\n",
    "\n",
    "The smoothing is applicable to general functions of the form\n",
    "\n",
    "$$\n",
    "g(X\\beta-\\alpha) = g_{\\alpha}(X\\beta)\n",
    "$$\n",
    "\n",
    "where $g_{\\alpha}(z) = g(z-\\alpha)$ and is determined by a small\n",
    "quadratic term\n",
    "\n",
    "$$\n",
    "q(z) = \\frac{C_0}{2} \\|z-x_0\\|^2_2 + v_0^Tz + c_0.\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "\\begin{equation*} \\frac{L_{}}{2}\\|\\beta\\|^2_2 \\end{equation*} "
      ],
      "text/plain": [
       "identity_quadratic(0.500000, 0.0, 0.0, 0.000000)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epsilon = 0.5\n",
    "smoothing_quadratic = rr.identity_quadratic(epsilon, 0, 0, 0)\n",
    "smoothing_quadratic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{equation*} \\frac{L_{}}{2}\\|\\beta\\|^2_2 \\end{equation*}\n",
    "$$\n",
    "\n",
    "The quadratic terms are determined by four parameters with\n",
    "$(C_0, x_0, v_0, c_0)$.\n",
    "\n",
    "Smoothing of the function by the quadratic $q$ is performed by\n",
    "Moreau smoothing:\n",
    "\n",
    "$$\n",
    "S(g_{\\alpha},q)(\\beta) = \\sup_{z \\in \\mathbb{R}^p} z^T\\beta - g^*_{\\alpha}(z) - q(z)\n",
    "$$\n",
    "\n",
    "where\n",
    "\n",
    "$$\n",
    "  g^*_{\\alpha}(z) = \\sup_{\\beta \\in \\mathbb{R}^p} z^T\\beta - g_{\\alpha}(\\beta)\n",
    "\n",
    "is the convex (Fenchel) conjugate of the composition :math:`g` with the\n",
    "$$\n",
    "\n",
    "translation by $-\\alpha$.\n",
    "\n",
    "The basic atoms in `regreg` know what their conjugate is. Our hinge\n",
    "loss, `hinge_rep`, is the composition of an `atom`, and an affine\n",
    "transform. This affine transform is split into two pieces, the linear\n",
    "part, stored as `linear_transform` and its offset stored as\n",
    "`atom.offset`. It is stored with `atom` as `atom` needs knowledge\n",
    "of this when computing proximal maps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$$\\lambda_{} \\left(\\sum_{i=1}^{p} (\\beta - \\alpha_{})_i^+\\right)$$"
      ],
      "text/plain": [
       "positive_part((1,), lagrange=1.000000, offset=array([-1.]))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hinge_rep.atom"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\lambda_{} \\left(\\sum_{i=1}^{p} (\\beta - \\alpha_{})_i^+\\right)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hinge_rep.atom.offset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hinge_rep.linear_transform.linear_operator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we said before, `hinge_rep.atom` knows what its conjugate is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$$I^{\\infty}(\\left\\|\\beta\\right\\|_{\\infty} + I^{\\infty}\\left(\\min(\\beta) \\in [0,+\\infty)\\right)  \\leq \\delta_{}) + \\left \\langle \\eta_{}, \\beta \\right \\rangle$$"
      ],
      "text/plain": [
       "constrained_max((1,), bound=1.000000, offset=None, quadratic=identity_quadratic(0.000000, 0.0, array([-1.]), 0.000000))"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hinge_conj = hinge_rep.atom.conjugate\n",
    "hinge_conj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "I^{\\infty}(\\left\\|\\beta\\right\\|_{\\infty} + I^{\\infty}\\left(\\min(\\beta) \\in [0,+\\infty)\\right)  \\leq \\delta_{}) + \\left \\langle \\eta_{}, \\beta \\right \\rangle\n",
    "$$\n",
    "\n",
    "The notation $I^{\\infty}$ denotes a constraint. The expression can\n",
    "therefore be parsed as a linear function $\\eta^T\\beta$ plus the\n",
    "function\n",
    "\n",
    "$$\n",
    "g^*(z) = \\begin{cases}\n",
    "0 & 0 \\leq z_i \\leq \\delta \\, \\forall i \\\\\n",
    "\\infty & \\text{otherwise.}\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "The term $\\eta$ is derived from `hinge_rep.atom.offset` and is\n",
    "stored in `hinge_conj.quadratic`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hinge_conj.quadratic.linear_term"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let’s look at the smoothed hinge loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$$ \\sup_{u \\in \\mathbb{R}^{p} } \\left[ \\langle X_{}\\beta, u \\rangle - \\left(I^{\\infty}(\\left\\|u\\right\\|_{\\infty} + I^{\\infty}\\left(\\min(u) \\in [0,+\\infty)\\right)  \\leq \\delta_{}) + \\frac{L_{}}{2}\\|u\\|^2_2 + \\left \\langle \\eta_{}, u \\right \\rangle \\right) \\right]$$"
      ],
      "text/plain": [
       "affine_smooth(smooth_conjugate(constrained_max((1,), bound=1.000000, offset=None, quadratic=identity_quadratic(0.500000, 0.0, array([-1.]), 0.000000)),identity_quadratic(0.500000, 0.0, array([-1.]), 0.000000)), <regreg.affine.linear_transform object at 0x12135e550>, store_grad=True)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smoothed_hinge_loss = hinge_rep.smoothed(smoothing_quadratic)\n",
    "smoothed_hinge_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\sup_{u \\in \\mathbb{R}^{p} } \\left[ \\langle X_{}\\beta, u \\rangle - \\left(I^{\\infty}(\\left\\|u\\right\\|_{\\infty} + I^{\\infty}\\left(\\min(u) \\in [0,+\\infty)\\right)  \\leq \\delta_{}) + \\frac{L_{}}{2}\\|u\\|^2_2 + \\left \\langle \\eta_{}, u \\right \\rangle \\right) \\right]\n",
    "$$\n",
    "\n",
    "It is now a smooth function and its objective value and gradient can be\n",
    "computed with `smooth_objective`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiEAAAFlCAYAAAA9NjhgAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nCBEREZFQ/B9LaRdQdfpSmwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 648x432 with 1 Axes>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ax.plot(r, [smoothed_hinge_loss.smooth_objective(v, 'func') for v in r])\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiEAAAFlCAYAAAA9NjhgAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nOzdd1yW9R7/8df3XmwVBVwMtdQcOXFg\nnrKhoA1bx5OnRHGgIu7cqaWV7ZRUQNnaPG3LQLNhmahomiu3TFHcC+EGrt8fcX4/fx1LMuTL+Dwf\nDx7Jdd3cvDwj34/7vi5UhmEghBBCCFHRTLoDhBBCCFEzyQgRQgghhBYyQoQQQgihhYwQIYQQQmgh\nI0QIIYQQWsgIEUIIIYQWFt0B1+Lh4WE0adJEd4YQQgghysHWrVtPGobh+fvjlXKENGnShLS0NN0Z\nQgghhCgHSqn0ax2Xt2OEEEIIoYWMECGEEEJoISNECCGEEFrICBFCCCGEFjJChBBCCKGFjBAhhBBC\naCEjRAghhBBayAgRQgghhBYyQoQQQgihxXVHiFLKRyn1rVJqj1Jqt1Jq/DUeo5RSEUqpg0qpX5RS\nna46N1gpdaD0Y3B5/waEEEIIUTWV5ce2FwGTDcPYppRyA7YqpdYahrHnqsf0BZqXfnQDIoFuSqm6\nwFzAHzBKv/ZzwzDOlOvvQgghhBBVznVfCTEM45hhGNtKf30B2As0/t3D+gNJxm9SgTpKqYZAILDW\nMIzTpcNjLRBUrr+DMiosuMLW1bE6vrUQQgghruEvXROilGoCdAQ2/e5UYyDzqs+zSo/90fFrPXeo\nUipNKZWWl5f3V7LK5OdPF9F58yQ2xkzEKCkp9+cXQgghxF9T5hGilHIFPgImGIZxvrxDDMNYZhiG\nv2EY/p6e//O3/f5t/o9NZrP7/QRkxZG6fKwMESGEEEKzMo0QpZSV3wbI24ZhfHyNh2QDPld97l16\n7I+OVzizxYJ/+Ao21XuYgGMr2RQ1UoaIEEIIoVFZ7o5RQCyw1zCMN/7gYZ8DwaV3yXQHzhmGcQxI\nAfoopdyVUu5An9JjFc6enU3uzJn4D1lMqte/6H7iAzYvCaGkuFhHjhBCCFHjleXumDuAQcBOpdT2\n0mMzAV8AwzCigNVAP+AgcBkIKT13Wik1H9hS+nXzDMM4XX75ZZe/ezfnVn1BYWYW/lGRbHzXgYBj\nSWxebKfzmCTMlrL8RyGEEEKI8qIMw9Dd8D/8/f2NtLS0cn/e8199RfbTU3Bs2waf6GjSPpxH96xY\n0mr1psPYd7BYbeX+PYUQQoiaTim11TAM/98fr1E/MbVW3754L1rIlT17yRw2nC6Pz2Gj3yj8z69l\nR8QA7IUFuhOFEEKIGqNGjRAAt/vuw/utCAoOHCB98BC69J9G6i3j6XzhW3YtepTCgiu6E4UQQoga\nocaNEAC3Xr3wXrqUwqNHSQ8Oxj9oLKktptDx0o/sWdifK/mXdCcKIYQQ1V6NHCEArj3vwCc6Gnt2\nDunBg+l87wg2tX6GDvmp7F/0IFcuX9SdKIQQQlRrNXaEALh074ZvzHKKTpwgfVAwnXo+yZZ282ib\nv42Di+7n8sVzuhOFEEKIaqtGjxAA586d8Y2LpfjMGdIHBdO+62Ns7fQira7s4Oiiflw8L3/XnhBC\nCHEz1PgRAuDUvj2+8fEUX7z42xBp34/tXV+jReEesiL6cv7sKd2JQgghRLUjI6SUU9s2+CUmYFy5\nQvqgYNq2uoedPRbSzL6f44sDOXfquO5EIYQQolqREXIVx9tuwy8pEcMwSB8UTKumAey5cyl+9iOc\nXBrEmbxjuhOFEEKIakNGyO84NG+OX1ISymwmI3gwtzVqz693L6NxUSZnIwM5mZupO1EIIYSoFmSE\nXINDs6b4rUhCOTmRPiSE5vVacrB3HPWLc7m0LIiTOem6E4UQQogqT0bIH7D5+eG3YgVmV1cyQkJo\n5uLD0b5JeBSfJH95EMezDulOFEIIIao0GSF/wubdGL+VKzDXq0vmsOE0sXiQ+cDb1Ck5Q3FsX3KO\n7tOdKIQQQlRZMkKuw9qwIX5JK7A0aEDGiFB8il051v99XI2LmBLuJ/vwbt2JQgghRJUkI6QMrPW9\n8EtKxObtTebIUTS6bCHv0Q9x4ArWpAfI2L9dd6IQQghR5cgIKSOLhwe+SYnYmjUja/RovE4XcnbA\nJ5gpxvmd/qTv3ao7UQghhKhSZIT8BRZ3d/zi43Bo2ZKsseOol32WiwM/x0Dh9v7DHN61SXeiEEII\nUWXICPmLzHXq4Bsfh1Pr1mRPmIj74WNceWoVdqzU/fBRDmz/QXeiEEIIUSXICLkBZjc3fGJjcerY\ngezJT1NrzxGKB68mHyfqfzqAfWnf6E4UQgghKj0ZITfI7OqC77JlOHftSs606Thv240a+hUXlBuN\nV/2bXzet0Z0ohBBCVGoyQv4Gk7MzPlGRuPTowbFZz+Dw01asw1M4Y3LHd/VT7N7wpe5EIYQQotKS\nEfI3mRwd8V66BNdevch99jks637EaWQKJ8xeNFszhJ3rP9OdKIQQQlRKMkLKgcnBAe+IRbj1vo/j\nL76I+vJrao1K4Zi5ES3WDWPHNx/oThRCCCEqHRkh5UTZbDR+4w3c+gZx4tVXKfl4FXXDUsi0+NLq\n+1H8vGal7kQhhBCiUrHoDqhOlNVK41dfJcdqJW/hIjwK7XiMSeHI0vtpu2EcW4vsdO4XojtTCCGE\nqBRkhJQzZbHQaMEClNXKyaVLqWe30zD8Kw4ueYAOmyaSVlyI/4MjdWcKIYQQ2skIuQmU2UzD+fNR\nViunli+nbmEhPmNX8+vih+iUNo3NRYV0fWSs7kwhhBBCKxkhN4kymWgwdy7KauN0YiKG3U7TiV+w\ne/HDdN3xDJuKCun2z8m6M4UQQghtrjtClFJxwAPACcMw2l7j/BTgyauerxXgaRjGaaXUUeACUAwU\nGYbhX17hVYFSivozZ6BsVk7HxmHYC7l1+ufsWPwo3XbPY1OJnW7/mq47UwghhNCiLK+EJACLgaRr\nnTQM41XgVQCl1IPARMMwTl/1kLsNwzj5NzurLKUUXk8//dtbM1HRGPYiWs7+mJ+XDKDb3gWkvl1A\n9yfn6s4UQgghKtx1b9E1DGM9cPp6jys1EHj3bxXdJMUlxfyU/ZOW762UwmvCBDzGjeXcp59yas5z\ntAn/kG2ud9L9wBtsTJyppUsIIYTQqdx+TohSyhkIAj666rABrFFKbVVKhZbX97oRH+7/kJFfjyRx\nd6K2Bs+wMDwnTeL8l19yYsYsbg97jzS3ewk4soSNcVMwSkq0tQkhhBAVrTwvTH0Q2PC7t2J6GoaR\nrZTyAtYqpX4tfWXlf5SOlFAAX1/fcsz6zaMtHmXL8S28lvYahcWFjGg3oty/R1l4hI5A2ayceOll\nDLud9q+tZEt0CAEZy9gYW0j3YW+iTPIz5IQQQlR/5fmn3RP87q0YwzCyS/95AvgE6PpHX2wYxjLD\nMPwNw/D39PQsx6zfWE1WXvrHSzzQ7AEifo5g6falGIZR7t+nLOoNGUL92c9w8ZtvODZhAh1D49hc\n90ECshPYFB0mr4gIIYSoEcrllRClVG3gLuCpq465ACbDMC6U/roPMK88vt+NspgsPH/H81hMFiJ3\nRFJYXMj4TuNRSlV4S90nn0RZreTOfZacsWPpFBHFpgQr3Y+/y6ZIO11HL5dXRIQQQlRrZblF912g\nF+ChlMoC5gJWAMMwokof9giwxjCMS1d9aX3gk9I/4C3AO4ZhJJdf+o0xm8w81+M5bCYbsbtiKSwp\nZIr/FC1DxH3AAJTVxrFZs8geHYb/0iWkrnT4bYgssdMlLB6T2VzhXUIIIURFuO4IMQxjYBkek8Bv\nt/Jefeww0P5Gw24mkzLxTPdnsJqtrNizAnuxnRndZmBSFf/KQ51HHkZZreRMm0Zm6Ej8o6PY+J6N\ngJxENr/1FJ3DV2C2yM+UE0IIUf3U2D/dlFJM6zINq8lKwu4E7CV25gTM0TJEaj9wP8pqJXvyZDKH\nj6BLdBQbP7YRkLmctIh/0WHsu1istgrvEkIIIW6mGn3RgVKKSZ0nMeL2EXx04CNmb5hNcUmxlpZa\ngX3wjlhEwd69ZAwbRpdHZ5HaZAz+57/ml0WPYy8s0NIlhBBC3Cw1eoTAb0NkXKdxhHUI4/NDnzPz\nx5kUlRRpaXG75x68lyym8OAhMgYPwf/ByaTeOpFOF79n16JHKSy4oqVLCCGEuBlq/Aj5r9HtRzO+\n03hWH1nN1PVTsZfYtXS43nknPlGRFGZkkB48mM59wkhtOY2Ol35k78KHuJJ/6fpPIoQQQlQBMkKu\nMvz24Uzxn8La9LVM/m4yhcWFWjpcevTAZ1k09mPHyBgUTOe7h7KpzWza529i/6IHyb90QUuXEEII\nUZ5khPxOcJtgZnabybeZ3zLh2wkUFOu5FsOla1d8Y5ZTdPIk6YOC6dRjIJvbz6dt/jYOL7qfyxfP\naekSQgghyouMkGsYeNtA5gbM5cfsHwlfF05+Ub6WDudOnfCNi6X47FmODhpEB/9H2NZ5AbcV/EL6\nor5cPH9GS5cQQghRHmSE/IHHWzzO/Dvmszl3M2Ffh3HZfllLh1P79vgmxGNcukz6U4O4/fYgtnd7\nneaFe8mOCOLcmZNauoQQQoi/S0bIn+h/a38W9FzAzyd+ZtTXo7hYeFFLh1ObNvgmJWIUFpIeHEzb\nlr34pUcETe0HOLE4kHOnjmvpEkIIIf4OGSHX0a9ZP1658xV25u0kdG0o5wvPa+lwbNkSv6REMCB9\nUDCtm3Rjz51L8Ss6ysmlgZw+ka2lSwghhLhRMkLKoE+TPrze63X2nt7L8JThnL1yVkuHQ/Pm+CUl\noSwWMgYP5raG7dh3z3IaF2VxPiqIk7kZWrqEEEKIGyEjpIzu8b2HiLsjOHT2EMPWDONU/iktHQ7N\nmuK3cgXK2Yn0ISHcWrc5B/vE41V8nMvLgsjLOaqlSwghhPirZIT8Bf/w/geL711MxvkMhqUMI+9y\nnpYOm68vfkkrMNeqRUbIUJo5eXO0bxL1ik9RsDyI3MyDWrqEEEKIv0JGyF8U0CiApfctJedSDkNT\nhnL8kp6LQm3ejfFbkYSlXj0yhg+nibkemQ++Qy3jHCVxfck58quWLiGEEKKsZITcgC4NuhDdO5q8\n/DyGJA8h52KOlg5rw4b4rkjC2qABGSNC8bE7c7z/+7gYlzAl3k/WwV1auoQQQoiykBFygzp6dWRZ\n72WcKzhHSHIImRcytXRYvbzwW5GEzceHzFGjaXhRcfLRD3GgEIeVD5C+b7uWLiGEEOJ6ZIT8De08\n2xETGMOlokuEJIdw9NxRLR2WevXwTUrE1qwZWWFj8DpZwNkBH6MwcH33IY7s2aKlSwghhPgzMkL+\nptb1WhPbJxZ7iZ2QlBAOnz2spcPi7o5fQjwOt91G1rhx1Ms6w6WBn1GCiTofPMqhnalauoQQQog/\nIiOkHLSs25K4wDgMwyAkJYT9Z/Zr6TDXro1vXCxObduSPXESdQ5mU/DUFxRgw+OjRznw83otXUII\nIcS1yAgpJ7fUuYX4oHgsysKwlGHsPbVXS4fZzQ2fmBicO3YkZ8pUXHcdpGTwl1xSLjT4dAC/pq3T\n0iWEEEL8noyQctS0dlPig+JxtDgybM0wdp3Uc3eK2dUFn2XROHftyrEZM3HeugtTyGrOmergs+rf\n7N2UoqVLCCGEuJqMkHLmW8uXhKAEatlqMWLNCLaf0HN3isnZGZ+oSFx69uTYM7Nx2JCGw4hkTpnr\n4bd6ELs2rNLSJYQQQvyXjJCboLFrYxKCEqjrWJeRa0eSlpumpcPk6Ij3ksW43n03uc/Nw/z1epxD\nUzhhrs+ta0LY+f3HWrqEEEIIkBFy0zRwaUB8UDz1XeoTti6M1GN67k4x2Wx4L1qIW+/eHH9xAerL\nNdQalUy2xZuW34xgxzfvaekSQgghZITcRF7OXsQFxtHYtTHh68LZkL1BS4ey2Wj8xuvU6tePE6++\nRslHn+MRlkK6pQmtvg/j5zUrtXQJIYSo2WSE3GQeTh7EBcbRtHZTxn4zlu8zv9fSoaxWGr36CrX7\nP0TeoggK334fzzHJHLE2p+2GcWxdHa+lSwghRM0lI6QCuDu6E9MnhhbuLZjw3QTWpeu5TVaZzTR8\n8UVqP/4YJ5dGUhiXSKOxX3HQdhsdNk0k7fMoLV1CCCFqJhkhFaS2Q22W91lOm3ptmPz9ZJKPJGvp\nUGYzDefNo87AJzgVE8vlpdH4jlvNrw7t6LR1Ops/idDSJYQQoua57ghRSsUppU4opa75Qy+UUr2U\nUueUUttLP+ZcdS5IKbVPKXVQKTW9PMOrIjebG9G9o2nv2Z5pP0xj1SE9t8kqk4kGc+bgHjyI04lJ\nXHgzgqZjV7HLqRNdd8xm039e09IlhBCiZrGU4TEJwGIg6U8e84NhGA9cfUApZQaWAL2BLGCLUupz\nwzD23GBrteBidSHyvkjGfTOOWT/OoqikiEeaP1LhHUop6s+YgbJaOR0bh2G303z6Z+xY/Bjdds8n\ntaiQ7gNnVniXEEKImuO6r4QYhrEeOH0Dz90VOGgYxmHDMAqB94D+N/A81Y6z1ZnF9y4moFEAc36a\nwwf7PtDSoZTC6+mn8Qgbzdn/fMiZeS9w29hP+Nn5Drrve5nUlXO1dAkhhKgZyuuakACl1A6l1FdK\nqTalxxoDmVc9Jqv0mAAcLY5E3BPBXd53MT91Pm/vfVtLh1IKz3Hj8Bw/jnOffcbJZ+bQZswHbHXt\nRfeDC9mYUOPfRRNCCHGTlMcI2Qb4GYbRHngL+PRGnkQpFaqUSlNKpeXl5ZVDVuXnYHbgzV5vcq/v\nvby0+SXid+m7TdZj9Gi8np7M+dWrOTF9Ju3C3iGtVm8CjkayMXYyRkmJtjYhhBDV098eIYZhnDcM\n42Lpr1cDVqWUB5AN+Fz1UO/SY3/0PMsMw/A3DMPf09Pz72ZVGVazlVfvepWgJkG8sfUNondEa2up\nN3w49WfO4MLateROnkL7UUlsrtOPgMwYUmPGyxARQghRrspyYeqfUko1AI4bhmEopbry27A5BZwF\nmiulmvLb+HgC+Pff/X7VkdVkZcE/FmA1WVm8fTH2EjtjOoxBKVXhLXWDg1FWK7nPzePYuPF0WhTD\nprgwAnKSSI0upNvISJRJ7uwWQgjx9113hCil3gV6AR5KqSxgLmAFMAwjCngcGK2UKgLygScMwzCA\nIqVUOJACmIE4wzB235TfRTVgMVmYf8d8rGYr0b9EYy+xM6HTBC1DxH3gQJTVyrHZc8geE47/4iWk\nJlrpfvw9Ni0tpMvoGExmc4V3CSGEqF6uO0IMwxh4nfOL+e0W3mudWw2svrG0msdsMjM3YC5Wk5W4\nXXEUFhcytctULUOkzuOPo6xWcmbMJHPUKPwjI0l920b33LfZvMSO/5hEGSJCCCH+lr/9dowoXyZl\nYla3WVhNVlbuXYm9xM7MbjMxqYp/C6R2//4oq5XsKVPJGhGKf3QUGz+wEZAdz5aIf9Np7NuYLfI/\nISGEEDdG/gSphJRSTO0yFavZSvyueIpKipgTMEfLEKnVrx9YLGRPfprM4SPoGrOcjR/ZCMiIJi3i\nX3QY+y4Wq63Cu4QQQlR9coVhJaWUYmKniYxsN5KPDnzE7A2zKS4p1tJSq08fvBctouDXX0kfEkKX\nR2awsWk4/ue/5pdFj2EvLNDSJYQQomqTEVKJKaUI7xjOmA5j+PzQ58z4YQZFJUVaWtzuuRvvpUso\nPHyYjMFD6PLAJFKbT6bTxfXsWvgwBVcua+kSQghRdckIqQJGtR/FxM4T+eroV0xdPxV7sV1Lh+s/\n/oFPVCSFGRmkBw+mc+9RbGo1g46Xf+LXhQ9x5fJFLV1CCCGqJhkhVcTQtkOZ2mUqa9PXMum7SRQW\nF2rpcAkIwHf5MuzHjpExKJhOdw1hU5s53J6fxoFFD5B/6YKWLiGEEFWPjJAqZFDrQczqNovvsr5j\n3LfjuFJ0RUuHc5cu+MbEUHTqFOlPDaJjwBNs7fg8ba5s5/Cifly6cFZLlxBCiKpFRkgV88RtT/Bs\nwLP8lP0T4d+Ek1+Ur6XDuVNHfOPjKD5/nvTgQbTv9BDb/F/mtoKdZET05cK5G/mLl4UQQtQkMkKq\noMdaPMbzPZ9nS+4Wwr4O47Jdz0WhTrffjl9CPMblfNKfGsTtbfqwvdub3Fq4j5y3gjh35qSWLiGE\nEFWDjJAq6qFbHuKlf7zEzyd+ZuTakVwo1HMthmPr1vgmJmIUF5MeHEzbFv9g1x0RNLUf5MTiQM6e\nzNXSJYQQovKTEVKF9W3al1fvepVdJ3cRuiaUcwXntHQ4tmyBX1IiSinSgwfTyq8Le++KwrcondNL\nAzl94g//8mQhhBA1mIyQKq63X2/evPtN9p3Zx4g1Izhz5YyWDodbbsFvRRLKZiMjeDAt6rdh/z3L\naFSczfmoQE7mZmjpEkIIUXnJCKkGevn0IuKeCA6dPcSwNcM4lX9KS4etSRP8ViRhcnEhY0gIt9a5\nhYN94vEqPkF+dCAnso9o6RJCCFE5yQipJno27smS+5aQeT6ToSlDybucp6XD5uOD34okzHXqkDF0\nGM2cGpPebwXuJWcojAkiN+OAli4hhBCVj4yQaqR7w+4svW8pxy4dIyQlhNxLei4KtTZujN/KFVg8\nPckYPgJf3Ml+8B1qGecx4vqSfXivli4hhBCVi4yQaqZLgy5E947mZP5JQpJDyLmYo6XDWr8+vkmJ\nWBs1JHPkSLwLHTn+8Ac4kY8l6X4yD+7U0iWEEKLykBFSDXX06sjy3ss5V3iOIclDyLyQqaXD6uWF\nX2IiNl9fMkeNpuG5Ek499hE27DiufJD0X7dp6RJCCFE5yAippm73vJ2YPjFcLrrMkOQhHD13VEuH\npV49fBMTsN16C5nhY/E6cYlz//oEhYHrew9zZM8WLV1CCCH0kxFSjbWu15q4wDiKSooISQnh0NlD\nWjos7u74xcfj2KoVWeMnUDf9FJf//RnFmKnzwSMc+uUnLV1CCCH0khFSzbVwb0FcYBwAQ1OGsv/M\nfi0d5tq18Y2Lxen228mePJna+7IofGoVBTjg8fHjHPh5vZYuIYQQ+sgIqQFuqXML8YHxWEwWhqUM\nY+8pPXenmF1d8Y1ZjnPHjuRMm4brzoOUDFnNJeVKg08H8OuWr7V0CSGE0ENGSA3RpHYTEoIScLI4\nMWzNMHbm6bk7xeTigs+yaJy7deXYzJk4bfkF09DVnDPVweeLJ9mz8SstXUIIISqejJAaxMfNh4Sg\nBGrbajNi7Qi2n9iupcPk7IxPZCQuPXuSO3sOth824zAimZNmD5okD2bXD59p6RJCCFGxZITUMI1c\nGxEfFI+nkyeha0PZkqvn7hSToyPeSxbjes89HJ83H/Pa73EJTea4uQG3fj2MX777SEuXEEKIiiMj\npAZq4NKAuMA4Gro0JOzrMDbmbNTSYbLZ8F74Jm59+nB8wUuwKpk6o1PItvhw27ehbF/3npYuIYQQ\nFUNGSA3l6exJXGAcPrV8CF8Xzg9ZP2jpUDYbjd94nVr330/e629Q9J9P8AhLJt3alNbrw9iWskJL\nlxBCiJtPRkgNVs+pHnF94rilzi2M/3Y832Z8q6VDWSw0euVlavfvz8mItyhY8S5eY5I5bG1Bu5/G\nsfXLGC1dQgghbi4ZITVcHcc6LO+znJbuLZn03STWpq/V0qHMZhoueJE6/3ycU1HRXImJp/HY1ey3\ntabD5qdJ+zxSS5cQQoib57ojRCkVp5Q6oZTa9Qfnn1RK/aKU2qmU+kkp1f6qc0dLj29XSqWVZ7go\nP7UdarOszzLaerRlyvdTWH14tZYOZTLR4LnncP/3vzkdG8elJVH4jfuSvY7t6bR1Bls+XqSlSwgh\nxM1hKcNjEoDFQNIfnD8C3GUYxhmlVF9gGdDtqvN3G4Zx8m9VipvOzeZGVO8owteFM+PHGdhL7PS/\ntX+FdyiTifqzn0FZrZxOTMQoLOSWp1exa/EjdPllDpuKCuk2YEqFdwkhhCh/130lxDCM9cDpPzn/\nk2EYZ0o/TQW8y6lNVDAXqwtL7l1ClwZdmL1hNh/t13ObrFIKr+nTqDdiOGffe58zC16mefgnbHfq\nTrc9z5P67gtauoQQQpSv8r4mZBhw9Y+8NIA1SqmtSqnQcv5e4iZwtjqz+J7F9Gjcg2c3Pst7v+q5\nTVYpheekSXiEhXHuo485Pe95WoV/xM8uPem+7xVSV8zR0iWEEKL8lOXtmDJRSt3NbyOk51WHexqG\nka2U8gLWKqV+LX1l5VpfHwqEAvj6+pZXlrgBjhZHIu6OYPL3k3lh0wvYS+wMaj2owjuUUniOG4uy\nWclbuAiKimgz/322Rj1F90OL2JhQSMCQlyq8SwghRPkol1dClFLtgBigv2EYp/573DCM7NJ/ngA+\nAbr+0XMYhrHMMAx/wzD8PT09yyNL/A02s4037nqD3n69eWXLK8TujNXW4jFqFF5TpnB+9VecmD6D\ndqPfZkvtPgQcjSQ1ZhJGSYm2NiGEEDfub48QpZQv8DEwyDCM/Vcdd1FKuf3310Af4Jp32IjKyWq2\n8sqdr9C3aV8WbltI1I4obS31hg2l/syZXFj7NbmTnqZDaAKb6/Sje1YsqcvHyhARQogq6Lpvxyil\n3gV6AR5KqSxgLmAFMAwjCpgD1AOWKqUAigzD8AfqA5+UHrMA7xiGkXwTfg/iJrKYLCzouQCrycqS\n7Uuwl9gJ7xBO6X+vFapu8CCUzUrus89xbNx4OkXEsCkujIBjK0mNstNtVBTKJD/6RgghqorrjhDD\nMAZe5/xwYPg1jh8G2v/vV4iqxmwyM/+O+VhNVpb9sgx7sZ2JnSdqGSLuTzyBslo59sxsssPG4L9k\nCalJNrqfeJ9NS+10GR2DyWyu8C4hhBB/XbldmCqqN5MyMSdgDhaThfjd8dhL7EztMlXLEKnz2GMo\nq5Wc6TPIHDUK/8hINr5jI+DYSjYvLsQ/PEmGiBBCVAEyQkSZmZSJWd1mYTVZWbl3JfYSOzO7zcSk\nKv4tkNoPPYSyWMieMpWs4SPoEh3Fxg9tBGTFsSViIJ3GvoPZIv/zFkKIykz+LS3+EqUUU7tMxWa2\nEbcrDnuJnTnd52A2VfwrDydPrMIAACAASURBVLX69QOrlexJk8kcPoKuMcvZ+ImNgPQoti76J+3H\nvY/FaqvwLiGEEGUjV/GJv0wpxYROExjVfhQfH/iY2RtmU1RSpKWlVu/eeEcsomDfPtKHhNDl4emk\nNhtH5wvf8MvCxygsuKKlSwghxPXJCBE3RCnFmA5jGNtxLKsOr2LGD7/9fTM6uN19N96RkRQeOUJG\ncDD+/caT2uJpOl1az55FD1Nw5bKWLiGEEH9ORoj4W0LbhTK582SSjyYz5fsp2Iv1DBHXnnfgEx1F\nYVY26cGD6XzvSDa1mkmHyxvZt/Ahrly+qKVLCCHEH5MRIv62IW2HML3rdNZlrGPidxMpKC7Q0uHS\nvTu+y5dRlJtLevAgOt0ZzObbn6VtfhoHF93P5YvntHQJIYS4Nhkholw82epJZnefzfdZ3zP+m/Fc\nKdJzLYazvz8+sTEUnzpN+qBgOnQbwNaOL9Dqyg6ORtzPxfNnrv8kQgghKoSMEFFuBrQcwLwe8/gp\n5yfC14Vz2a7nWgznjh3xjY+n+Px50gcNon3HB/i566u0KNhNVkRfzp89df0nEUIIcdPJCBHl6pHm\nj/BCzxfYcnwLo78ezSX7JS0dTre3xS8xASM/n/RBwdze6l5+CXiTW+z7yV0cxLnTeVq6hBBC/D8y\nQkS5e/CWB3n5Hy+zI28HI9eO5ELhBS0djq1a4ZuUiFFcTHrwYFo368Hufyyhif0weUsCOZN3TEuX\nEEKI38gIETdFUNMgXrvrNXaf2k3omlDOFei5KNSxRQv8ViShlCJj8BBu8+7Ir72i8SnK4GxkEKeO\nZ2npEkIIISNE3ET3+d3Hwl4L2XdmH8PXDOfMFT0XhTo0a/bbEHFwIH3wEJp7tuLAfbE0KM7hYnQQ\nJ3PStXQJIURNJyNE3FR3+dzFW/e8xZFzRxiaMpST+Se1dNiaNMFv5QrMrq5khIRwi5sfhwMT8Sw+\nQf7yII5nHdLSJYQQNZmMEHHT3dH4Dpbcu4Tsi9kMTRnKicsntHTYvL3xW5GE2d2djKHDaOpQn4z7\n38a95AxFsX05lr5PS5cQQtRUMkJEhejWsBuR90Vy/NJxQpJDyL2Uq6XD2qgRfiuSsNSvT8bwEfgY\ntcnp/x5uxkVU/P1kH96rpUsIIWoiGSGiwnSu35no3tGcvnKaIclDyL6YraXDWr8+fkmJWBs3IjM0\nlEaXrZx45AMcycea1I/MAzu0dAkhRE0jI0RUqA5eHVjeZznnC88TkhxC5vlMLR0WT0/8kpKwNW1K\nVlgYDc4Wc/rxj7FQhNPbD5G+d6uWLiGEqElkhIgK19ajLbF9YskvymdI8hCOnDuipcNSty5+CfE4\nNG9OZvhYPHMvcOFfnwLg9v7DHNm9SUuXEELUFDJChBat6rUiNjCWIqOIkOQQDp45qKXDXKcOvvFx\nOLZuRdaEibin55H/5OcUYaHOfx7j4I4NWrqEEKImkBEitGnh3oL4wHhMysTQlKHsO63n7hRzrVr4\nxsbi1L492ZMmU+vXDOzBX1CAI16f/JP9277X0iWEENWdjBChVbM6zYgPisdmtjFszTD2nNqjpcPs\n6orvsmicu3QhZ+o0XH7ehxHyJReVKw0/+xe/bl6rpUsIIaozGSFCO79afiQEJeBicWF4ynB+yftF\nS4fJxQWfqEhcevTg2KxZOKbuwDzsK86a3PH98kn2bPxKS5cQQlRXMkJEpeDt5k1CUAJ1HOsQujaU\nbce3aekwOTnhvXQJrnfdRe7cuVi/S8VpRDJ5Zi+aJgez64fPtHQJIUR1JCNEVBoNXRsSHxiPp5Mn\no74exZbcLVo6TA4OeL8Vget993L8+edRKd/iOjKZXHMjbv16GL98+6GWLiGEqG5khIhKpb5LfeKD\n4mnk0oiwr8P4KecnLR3KZsP7zTdxCwrixMsvY3y6mjqjk8m2+HDbdyPZ/vW7WrqEEKI6kREiKh0P\nJw/iguLwreXL2HVjWZ+1XkuHslpp/Nqr1HrwQfLefJOi9z+mXlgKR63NaPPDGLYlJ2jpEkKI6kJG\niKiU6jrWJbZPLLfUuYXx347nm4xvtHQoi4VGLy2g9iOPcHLxYgqT3qH+mK84ZGtJu40TSftimZYu\nIYSoDso0QpRScUqpE0qpXX9wXimlIpRSB5VSvyilOl11brBS6kDpx+DyChfVXx3HOsQExtC6bmsm\nfzeZlKMpWjqU2UzDF56nzoABnIqO5sqyOBqHf8l+hzZ03DKVLZ8u0dIlhBBVXVlfCUkAgv7kfF+g\neelHKBAJoJSqC8wFugFdgblKKfcbjRU1Ty1bLaJ7R3O75+1MXT+VLw9/qaVDmUw0eO5Z3J98ktPx\n8Vx6KxK/sV+w17E9nX+exeaPFmrpEkKIqqxMI8QwjPXA6T95SH8gyfhNKlBHKdUQCATWGoZx2jCM\nM8Ba/nzMCPE/XG2uRN0XRef6nZnxwww+O6jnNlmlFPWfmUXdIUM4s3Il5199k1vGrmKXkz9dd85l\n0/sva+kSQoiqqryuCWkMXP3XoWaVHvuj40L8Jc5WZ5bcu4TuDbsze8NsPtyv5zZZpRRe06ZSLzSU\nsx98wJkXXqLF2E/42bkH3fa+SOo787V0CSFEVVRpLkxVSoUqpdKUUml5eXm6c0Ql5GRx4q1736Jn\n4548t/E53tn7jpYOpRSeEyfgER7OuU8+4dTcebQe8x+2udxJ9/2vsTFptpYuIYSoasprhGQDPld9\n7l167I+O/w/DMJYZhuFvGIa/p6dnOWWJ6sbB7MDCuxdyt8/dLNi8gMTdiVo6lFJ4ho/Bc+JEzn/x\nBXmzZnP7mPfY6nYPAYcj2Bg/TUuXEEJUJeU1Qj4HgkvvkukOnDMM4xiQAvRRSrmXXpDap/SYEDfM\nZrbxeq/X6ePXh9fSXiNmZ4y2Fo+RoXhNm8aF5GRyp0yj3ei32VI7kID0KDbGTMQoKdHWJoQQlZ2l\nLA9SSr0L9AI8lFJZ/HbHixXAMIwoYDXQDzgIXAZCSs+dVkrNB/7787fnGYbxZxe4ClEmVpOVl+98\nGesGK4u2LcJebGdU+1EopSq8pV7IEJTVyvHnn+fYxIl0fDOBzctHEJAVR+qyArqFLkaZKs07n0II\nUWmUaYQYhjHwOucNYMwfnIsD4v56mhB/zmKy8MIdL2BRFpbuWEphSSHjOo7TMkTqPvUkymold+5c\ncsLH0ikimk0JY+me+zapUXa6jYqWISKEEL9TphEiRGVlNpmZd8c8rGYrMTtjsBfbmew/WcsQcf/X\nAJTFwrFnniE7bAz+SxaTusJK9xPvs2lJIV3C4jCZzRXeJYQQlZWMEFHlmZSJOd3nYDVZSdyTiL3E\nzvSu07UMkTqPPYqyWcmZNp3MUaPxj1zKxncdCDiWxOa3CukcvgKzRf5vJ4QQICNEVBNKKWZ0nYHV\nZCVpTxL2EjvPdH8Gk6r4t0BqP/ggymole/LTZI4YQZfoaDZ+ZCMgM4Ytbw2kY/jbWKy2Cu8SQojK\nRkaIqDaUUjzt/zQ2s+23t2ZK7Dwb8CxmU8W/BVIrKAhlsZA1cRKZw4bTNTaGjZ9aCTgaydaIAbQb\n+z5Wm0OFdwkhRGUiV8qJakUpxbiO4xjdfjSfHvyUWRtmUVRSpKXF7b778H4rgoIDB0gfPIQuD00l\n9dYJdL7wLbsWPUphwRUtXUIIUVnICBHVjlKKsA5hjOs4ji8Pf8n0H6ZjL7FraXHr1QvvpUspPHqU\n9OBg/APDSW05lY6XfmTPwv4UXLmspUsIISoDGSGi2hrRbgRP+z9NytEUpnw/BXuxniHi2vMOfKKj\nsWfnkB48mM73DGdT62fokJ/KvoUPcuXyRS1dQgihm4wQUa0NbjOY6V2nsy5jHRO+m0BBcYGWDpfu\n3fCNWU7RiROkDwqmU88n2dJuHm3zt3Jw0f1cvnhOS5cQQugkI0RUe0+2epI5AXNYn7Wecd+MI78o\nX0uHc+fO+MbFUnzmDOmDgmnf9TG2dnqRVld2cHRRPy6eP6OlSwghdJERImqEf7b4J/N6zGNjzkbC\n14Vz2a7nWgyn9u3xjY+n+OJF0p8aRPsO97O962u0KNxDVkRfzp89paVLCCF0kBEiaoxHmj/CCz1f\nIO14GqO/Hs0l+yUtHU5t2+CXmIBRUED6U4No2+oedvZYSDP7fo4vDuTcqeNauoQQoqLJCBE1yoO3\nPMjLd77MjrwdhK4N5XzheS0djrfdhl9SIoZhkD4omFZNA9hz51L87Ec4uTSIM3nHtHQJIURFkhEi\napygJkG8ftfr7Dm1hxFrRnCuQM9FoQ7Nm+OXlIQym8kIHsxtjdrz693LaFyUydnIQE7mZmrpEkKI\niiIjRNRI9/rdy8JeCzlw5gDDUoZx5oqei0IdmjXFb0USysmJ9CEhNK/XkoO946hfnMulZUHk5RzV\n0iWEEBVBRoiose7yuYvF9yzm6PmjDE0Zysn8k1o6bH5++K1YgdnVlYyQEJq5+HC0bxIexScpWB5E\nbuZBLV1CCHGzyQgRNVqPxj1Ycu8Ssi9mMzRlKCcun9DSYfNujN/KFZjr1SVz2HCamOuR+cDb1C45\nS0lcP3KO7tPSJYQQN5OMEFHjdWvYjcj7Ijl+6TghySHkXsrV0mFt2BC/pBVYGjQgI3QkPsWuHOv/\nPq7GRUwJ95N9eLeWLiGEuFlkhAgBdK7fmWV9lnHmyhmGJA8h60KWlg5rfS/8khKxeXuTOXIUjS6Z\nyXv0Qxy4gjXpATL2b9fSJYQQN4OMECFKtfdsz/LA5VwovEBISggZ5zO0dFg8PPBNSsTWrBlZYWF4\nnSrg7D8/wkwxzu/05+jeNC1dQghR3mSECHGVNvXaEBcYR0FRAUOSh3D43GEtHRZ3d/zi43Bo2ZKs\nceOpl3Oei098ioGi9vuPcGhnqpYuIYQoTzJChPidlnVbEhsYS4lRwtDkoRw4c0BLh7lOHXzj43Bq\n3ZrsCRNxP3KcK0+tohArHh89yoHtP2jpEkKI8iIjRIhraO7enLigOEzKxLCUYew7refuFLObGz6x\nsTh17ED25KeptecIxYNXcxln6n86gH1p32jpEkKI8iAjRIg/0Kx2MxKCEnCwODA0ZSi7T+q5O8Xs\n6oLvsmU4d+lCzrTpOG/bjRr6FedVLRqv+jd7N6Vo6RJCiL9LRogQf8K3li/xgfG42dwYvmY4O/J2\naOkwOTvjExWJS48eHJv1DA4/bcU2PJkzJnf8Vg9i94YvtXQJIcTfISNEiOvwdvMmPjAed0d3QteE\nsu34Ni0dJicnvJcuwfWuu8h99jks637EaWQKJ8xeNFszhJ3rP9HSJYQQN0pGiBBl0NC1IQlBCXg5\nezHq61FsPrZZS4fJwQHvtyJw630fx198EfXl17iNTCbX3IgW60aw45sPtHQJIcSNkBEiRBl5OXsR\nHxRPY9fGhK0L46fsn7R0KJuNxm+8Qa1+fTnx6qsYn3yBe1gKmRZfWn0/ip/XrNTSJYQQf5WMECH+\nAg8nD2IDY2lSqwnh34SzPmu9lg5ltdLolVeo9dCD5C1chP2d/+AxJoWj1ltou2Ec276K19IlhBB/\nRZlGiFIqSCm1Tyl1UCk1/Rrn31RKbS/92K+UOnvVueKrzn1envFC6FDXsS6xgbG0cG/B+G/Hsy59\nnZYOZbHQaMECaj/6KCeXLqUwfgUNwpM5ZGtJu9RJpK2K1tIlhBBldd0RopQyA0uAvkBrYKBSqvXV\njzEMY6JhGB0Mw+gAvAV8fNXp/P+eMwzjoXJsF0Kb2g61Wd5nOa3rtWby95NJPpqspUOZzTR8fj51\nnvgXp5YvJz9yOd5jV7PPoQ2d0qax5dPFWrqEEKIsyvJKSFfgoGEYhw3DKATeA/r/yeMHAu+WR5wQ\nlZmbzY1lvZfR3rM909ZPY9WhVVo6lMlEg7lzcR80iNOJiVxcuJimY79kt2MHOv/8DJs/fENLlxBC\nXE9ZRkhjIPOqz7NKj/0PpZQf0BS4+sc4Oiql0pRSqUqph2+4VIhKyMXqQuR9kfjX92fWj7P45ICe\n22SVUtSfOYO6Q4dy5p13OPfKa9w6bhU7nbvQdddzbHr/JS1dQgjxZyzl/HxPAB8ahlF81TE/wzCy\nlVLNgG+UUjsNwzj0+y9USoUCoQC+vr7lnCXEzeNsdWbJvUsY/+145vw0B3uJnQEtB1R4h1IKrylP\no2xWTkVFY9iLaDn7Y35eMoBuexeQ+nYh3Z+cU+FdQgjxR8rySkg24HPV596lx67lCX73VoxhGNml\n/zwMfAd0vNYXGoaxzDAMf8Mw/D09PcuQJUTl4WhxJOKeCO70vpP5qfN5e+/bWjqUUnhNmIDHuLGc\n+/RTTs15jjbhH7LN9U66H3idjYmztHQJIcS1lGWEbAGaK6WaKqVs/DY0/ucuF6XUbYA7sPGqY+5K\nKYfSX3sAdwB7yiNciMrGwezAwl4Ludf3Xl7a/BIJuxK0tXiGheE5eRLnv/ySE9NncnvYe6TVuo+A\nI4vZGDcFo6REW5sQQvzXdUeIYRhFQDiQAuwFPjAMY7dSap5S6uq7XZ4A3jMMw7jqWCsgTSm1A/gW\neMkwDBkhotqymq28eterBDYJ5PWtr7P8l+XaWjxGjMBr+jQurFlD7tNTaT9qBVvq9CUgYxmpsRNl\niAghtFP//2aoHPz9/Y20tDTdGULcsKKSImZvmM0Xh79gdPvRjG4/GqWUlpbTb7/N8fnP43LnP2j0\n5ptsix1J19OrSG3wJN1CF6NM8jMLhRA3l1Jqq2EY/r8/Xt4XpgohAIvJwvN3PI/FZCFyRySFxYWM\n7zReyxCp++STKKuV3LnPkjN2LJ0iotiUYKV77tukRhbSbfQyGSJCCC1khAhxk5hNZp7r8Rw2k43Y\nXbEUlhQyxX+KliHiPmAAymrj2KxZZI8aTefIpaSudKD78XfZtKSQLmHxmMzmCu8SQtRsMkKEuIlM\nysQz3Z/BarayYs8K7MV2ZnSbgUlV/CsPdR55GGW1kjNtGlmhI/GPjmLje1YCcpLY/NZTdA5fgdki\n/0oQQlQc+TeOEDeZUoppXaZhNVlJ2J2AvcTOnIA5WoZI7QfuR1ksZD/9NJnDR9AlOoqNH9sIyIwh\nLeJfdBj7LharrcK7hBA1k4wQISqAUopJnSdhNVlZvnM59hI783rMw2yq+LdAagUFoqwWsiZMJHPY\ncLrExpD6mQPdjy5h66J/0m7cB1htDhXeJYSoeeRqNCEqiFKKcZ3GMabDGD4/9Dkzf5xJUUmRlha3\ne+/FZ8liCg4eJGNICP4PTib11ol0vvgduxY9SmHBFS1dQoiaRUaIEBVsVPtRTOg0gdVHVjN1/VTs\nJXYtHa533olPVCSF6emkDx5M5z5hpLacRsdLP7J34UNcyb+kpUsIUXPICBFCg2G3D2OK/xTWpq9l\n0neTKCwu1NLh0qMHPtHR2HOOkRE8mM73DGNTm9m0z9/E/kUPkn/pgpYuIUTNICNECE2C2wQzs9tM\nvsv8jgnfTqCguEBLh0u3rvjGLKcoL4/0pwbRqcdANrefT9v8bRxedD+XL57T0iWEqP5khAih0cDb\nBjI3YC4/Zv9I+Lpw8ovytXQ4d+qEb1wsxWfPkj4omA7+j7Ct8wJuK/iF9EV9uXj+jJYuIUT1JiNE\nCM0eb/E48++Yz6ZjmxizbgyX7Ze1dDi1b49vQjwlly6R/tQg2rXry/Zur9O8cC/ZEUGcO3NSS5cQ\novqSESJEJdD/1v4s+McCth3fxqivR3Gx8KKWDqc2bfBNSsSw2zk6aBBtW/bilx4RNLUf4MTiQM6d\nOq6lSwhRPckIEaKSuL/Z/bxy5yvszNtJ6NpQzhXouRbDsWVL/JISwYD0QcG0btKNvXctxa/oKCeX\nBnL6RLaWLiFE9SMjRIhKpE+TPrze63X2nt7LiDUjOHvlrJYOh1tvxS8pCWWxkDF4MC0btGPfPctp\nXJTF+aggTuZmaOkSQlQvMkKEqGTu8b2HRXcv4tDZQwxbM4zTV05r6XBo1hS/lStQzk6kDwnh1rrN\nOdg7Dq/i41xeFkRezlEtXUKI6kNGiBCV0J3ed/LWvW+RcT6DoclDOZmv56JQm68vTVaswFyrFhkh\nQ2nm7MPRvknUKz5FwfJAcjMOaOkSQlQPMkKEqKR6NOrB0vuWknMph5DkEI5f0nNRqLVxY/xWJGGp\nV4+M4cNpYq5H5oPvUMs4T0l8P3KO/KqlSwhR9ckIEaIS69KgC1H3RZGXn0dISgjHLh7T0mFt2BDf\nFUlYGzQgY0QoPnZnjvd/HxfjEqbE+8k6uEtLlxCiapMRIkQl16l+J5b1XsbZK2cJSQkh60KWlg6r\nlxd+SYnYfHzIHDWahhcVJx/9EAcKcVj5AOn7tmvpEkJUXTJChKgC2nm2Y3ngci7aLzIkeQjp59O1\ndFg8PPBNSsTWrBlZYWPwOlnA2QEfozBwebc/R/Zs0dIlhKiaZIQIUUW0qdeG2D6xFBYXEpIcwuGz\nh7V0WNzd8UuIx+G228gaN456WWe4NPAzDBR1PniUQ7/8pKVLCFH1yAgRogppWbclcYFxlBglhKSE\nsP/Mfi0d5tq18Y2LxaltW7InTqLOwWwKnvqCAmx4fPw4B35er6VLCFG1yAgRooq51f1W4oPisSgL\nw1KGsffUXi0dZjc3fGJicO7YkZwpU3HbfYiSwV9ySbnQ4NMB/Jq2TkuXEKLqkBEiRBXUtHZT4oPi\ncbQ4MmzNMHad1HN3itnVBZ9l0Th37UrO9Bk4b92FKWQ150y18Vn1b/akJmvpEkJUDTJChKiifGv5\nkhCUQC1bLUasGcH2E3ruTjE5O+MTFYlLz54ce2Y2DhvScBiRwilzPZp8FcyuDau0dAkhKj8ZIUJU\nYY1dG5MQlEBdx7qMXDuStNw0LR0mR0e8F7+Fa69e5D43D/PX63EOTeGEuT63rglh5/cfa+kSQlRu\nMkKEqOIauDQgPiie+i71CVsXRuqxVC0dJgcHvCMW4da7N8dfXID6IoVao5LJtnjT8psR7PjmPS1d\nQojKS0aIENWAl7MXcYFxNHZtTPi6cDZkb9DSoWw2Gr/xOrX69ePEa69T/OFneISlkG5tSqvvw/h5\nzUotXUKIyqlMI0QpFaSU2qeUOqiUmn6N80OUUnlKqe2lH8OvOjdYKXWg9GNwecYLIf4fDycP4gLj\naFq7KWO/Gcv3md9r6VBWK41efYXa/R/iZMRbFKx8D68xyRyxNqfthnFsXR2vpUsIUflcd4QopczA\nEqAv0BoYqJRqfY2Hvm8YRofSj5jSr60LzAW6AV2BuUop93KrF0L8f9wd3YnpE0ML9xZM+G4C69L1\n3CarzGYaLlhA7ccf41RkFAWxCTQa+xUHbK3osGkiaZ9HaekSQlQuZXklpCtw0DCMw4ZhFALvAf3L\n+PyBwFrDME4bhnEGWAsE3ViqEKIsajvUZnmf5bSp14bJ308m+Yie22SVyUTDefOoM/AJTsXEcmlJ\nFH7jvuRXh3Z02jqdzZ9EaOkSQlQeZRkhjYHMqz7PKj32e48ppX5RSn2olPL5i18rhChHbjY3ontH\n08GrA9N+mMaqQ3puk1UmEw3mzKHu4GDOJK3g/BuLaDp2FbucOtF1x2w2/ec1LV1CiMqhvC5MXQU0\nMQyjHb+92pH4V59AKRWqlEpTSqXl5eWVU5YQNZeL1YWl9y6lS/0uzPpxFp8c+ERLh1IKr+nTqTdi\nOGfffY9zr7xG87GfscOpG912zyf13Re1dAkh9CvLCMkGfK763Lv02P9lGMYpwzAKSj+NATqX9Wuv\neo5lhmH4G/+nvfsOr6LO2z/+/iQ5CT0ghJ4EpCggSgkSFFeQDiugyyruI4HQm9h2WcWVVdRVVlYB\nEamhWncVxQbqWp+HYqKyVJGiSQhNQodA2vf3R7L7yyolkeRMyv26rlycM2cyc58vc5I7c2bmOBcV\nFhaWn+wichEVfBWY1WUW19W9jslrJvPqt696ksPMCLvvPmqMHcPRv/+DI1Oe4Mq7VvBNxY5Eb5/K\nuuV/9iSXiHgrPyUkHmhiZg3NLBgYCKzMO4OZ1clzty/w7w+zWA10N7NquQekds+dJiJ+Ui6oHDNu\nmsGN9W/k8fWPs3yrN6fJmhlhEyYQdvcEjr31Fof+NJkWY1/lq0qdiN45nXWLJ3mSS0S8E3SxGZxz\nmWY2npzyEAjEOee2mNkUIME5txKYYGZ9gUzgMDAk93sPm9lj5BQZgCnOucNF8DxE5AJCAkN4ttOz\nTPx8IlPjp5KRnUHsVbGeZKkxZgwWHMzBp6fhMjK4eupLJMwZTPQPz7N2YTrRsX/FAnQJI5GywJxz\nXmf4maioKJeQ4M3lp0VKs4zsDB764iHe/+F9xrcaz6hrRnmW5fDSpRz4y5NU6tyZ2n+bxjfzhnHt\n0fdYW3cw0cOnq4iIlCJm9pVzLuqn0y+6J0RESg9fgI8nb3iSoIAgZm2YRUZ2BuNajcPM/J7lspgY\nzOdj/6NT2DfhbtrMWMD6uDF02LuEdXPTaT9qtoqISCmnEiJSxgQGBPLY9Y/hC/Qxd+NcMrIzuKfN\nPZ4UkWp33IH5fOx7eDIp48YTNWs265f4iD7wMutnn6XdmAUEBAb6PZeI+IdKiEgZFBgQyJ87/Blf\ngI+4zXGkZ6Uzsd1ET4pI1QEDMJ+PvQ9OYs/oMbR9YTbrlucUkS+fzyBq3BIVEZFSSiVEpIwKsAAe\nav8QvgAfy7ctJyM7g0ntJxFg/n8LJLRfP8znI+UPE9kzYiRRc+ew9rUQOqQsJv65/6HN+OUEBunH\nlUhpo1e1SBlmZkxsNxFfoI9FmxeRmZ3J5A6TPSkiVXr3hqAgUu7/PcnDhtNu3lzWvhlCh6S5JMy8\nnVZ3vUyQL9jvuUSk6OioL5Eyzsy4t829jLp6FK/veJ2H/+9hsrKzPMlSpXt36s+cwdnt20kaNpx2\ntzzI2objiDr+ERtnDCAj/ezFFyIiJYZKiIhgZoxvPZ5xrcaxctdKHvziQTKyMzzJUrlzZ+rPnk36\n7t0kxQymXZ/7WNfk8TnFKwAAGExJREFUPtqc/IzN0/tz9sxpT3KJSOFTCRGR/xh9zWjubXsv7//w\nPn/8/I9kZHlTRCrd0JHwOS+QnpxMYsxg2nYbw/orH6D16TV8O6MfZ9JOeZJLRAqXSoiI/JehVw1l\nYruJfJj4Ifd9eh/pWeme5KjYoQMR8+eRuX8/SYNiaNMplvUtJtPydDw7pv+atFMnPMklIoVHJURE\nfmZQ80H8qf2f+HTPp0z4ZAJnMs94kqNCu3aEL1hAZmoqiXcOonWHgSS0eowWZ75h94zenDpx1JNc\nIlI4VEJE5Jxuv/J2Hr3uUdakrGH8x+NJy0zzJEeFNq2JWBRH1vHjJMYMolXbfnwdNZUrzm4maWYv\nThzTx1GJlFQqISJyXrc2uZXHOz5O/P54xnw0hlMZ3hyLUb5lSyIXL8KdTiNxUAwtr+rOxuhnaJy+\nnb3P9eTYkUOe5BKRS6MSIiIX1LdRX5664Sk2HNzA6A9HcyLdm2MxyjVvTsSSJbiMDBIHxdCiyQ1s\nvn4mDTN28uOs7hxLPeBJLhH55VRCROSiejXsxdM3Ps3mQ5sZ+cFIjp095kmOclc0JXLpEjBIjBlM\ns8h2bLtxDuGZSaQ+353DB1M8ySUiv4xKiIjkS7fIbjzb+Vm2H9nOiA9GcOTMEU9yhDRuTOTSpZjP\nR1LMYJrWasF3XeZTNyuF43N6cGh/kie5RKTgVEJEJN86hXdi5k0z2X1sN8M+GEZqWqonOUIaNiRy\n+TKsYgWSYofSuGojdnZfRM2sg6TN7cHBlO89ySUiBaMSIiIF0rFeR2Z1mUXy8WSGrh7Kj6d/9CRH\ncHg4DZYtIzA0lKTYoVxevh6JvZdRLfsI6Qt6sj9phye5RCT/VEJEpMCi60Qzu+ts9p3aR+zqWPaf\n2u9JDl+9ekQuW0pQWBhJw0cQYdVIufklqrjjuLhe7P3+W09yiUj+qISIyC/SrnY75nWbR2paKrGr\nYtl7cq8nOXy1axOxdAm+unVIHjmK+unlOND/NcqTRuCS3iTv3ORJLhG5OJUQEfnFWtVsxbxu8ziW\nfowhq4aQfDzZkxy+mjWJXLKE4IgIkkePoc5xR+pvXieYDMotv5nEb7/2JJeIXJhKiIhckpZhLVnQ\nfQGnM08zZPUQfjj2gyc5gqpXJ2LJYoIbN2LPuPHU/PE0x29/E8NR6ZX+fL813pNcInJ+KiEicsma\nV29OXI84MrMziV0dy66juzzJEVStGpGLFhHSrBl7JtxNtcRDnP7dW2QRSNXXbmHXxjWe5BKRc1MJ\nEZFC0bRaU+J6xAEwdPVQth/e7kmOwNBQIuIWUr5lS1Luv5/Q71JIv/NtzhJCjTcGsOObzz3JJSI/\npxIiIoWmUdVGLOqxiKCAIIZ9MIytqVs9yRFYqRIRC+ZToU0b9k6cSKVNO8ke8h6nrBK137yNb+M/\n8iSXiPw3lRARKVQNQhuwuMdiKgRVYPgHw9n0ozdnpwRUrEj4vLlUjG7PvkmTKB+/kYCh73EsoCrh\n7/wPW9e+70kuEfn/VEJEpNCFVwlncc/FhAaHMuLDEWw4uMGTHAHly1P/hReoeENH9j88meAvviRk\nxCoOBdagwarBbP7iLU9yiUgOlRARKRJ1K9VlUc9F1Chfg5EfjiR+vzdnpwSEhFB/1iwq3XQTB6Y8\nRuCHn1Fx5CoOBNam8UfD2Pjp657kEhGVEBEpQrUr1mZRj0XUqViHsR+NZe3etZ7kCAgOpv70Z6nc\nvTsHnnwK3l5F1TGrSQkK58pPRrLhn694kkukrMtXCTGznma23cx2mtkD53j8PjPbamYbzeyfZhaZ\n57EsM9uQ+7WyMMOLSPEXViGMuB5xhFcJZ/w/x/PFni88yWHBwdR75m9U6dOHH//2DJl/X0GNsatI\n9DWkxedj+Wb1Ek9yiZRlFy0hZhYIPA/0ApoDd5hZ85/M9g0Q5Zy7GvgH8Nc8j6U551rlfvUtpNwi\nUoJUL1+duO5xNKraiLs/uZuPkz72JIcFBVH3r1MJ7dePQzOf4+yyl6k5bhW7fE1pueYevnp3gSe5\nRMqq/OwJuRbY6Zzb7ZxLB14B+uWdwTn3iXPudO7ddUD9wo0pIiVd1XJVmd99Ps0ua8b9n97P6h9W\ne5LDAgOp8+RfqPrbAaTOmcuZ+Yuod9d7fBfSglZf/p74t2Z7kkukLMpPCakH5P1AiD25085nGJD3\n3LdyZpZgZuvMrP8vyCgipURoSChzu83l6rCrmfj5RN7e9bYnOSwggNqPPkq1393B4bg4Ts2aQ+Rd\n77Ct3DW0/XoS8W/M8CSXSFkTVJgLM7M7gSjgxjyTI51zKWZ2OfCxmW1yzv3sms5mNhIYCRAREVGY\nsUSkGKkUXIkXur7AhE8m8ND/PkR6Vjq/afobv+ewgABqPfww5gvm8JIluIx0Gv3+bTbPupV2Gyez\nPvMs7W+b6PdcImVJfvaEpADhee7Xz532X8ysK/AQ0Nc5d/bf051zKbn/7gY+BVqfayXOuXnOuSjn\nXFRYWFi+n4CIlDwVfBWYddMsOtbryCNrH+HFbS96ksPMqPnAH6k+YgRHX3mVI09OpeldK9hQoQPt\ntz7Bupce9ySXSFmRnxISDzQxs4ZmFgwMBP7rLBczaw3MJaeAHMwzvZqZheTergFcD3hzHWcRKVbK\nBZVjeufpdInowlNfPsXzG57HOef3HGZG2H33UmPcOI69/gapjz5Gs3H/4OuKNxD93dOsWzbZ75lE\nyoqLvh3jnMs0s/HAaiAQiHPObTGzKUCCc24l8DRQCfi7mQEk5Z4J0wyYa2bZ5BSep5xzKiEiAkBw\nYDDTbpzGlLVTmPOvORw5c4QHr32QwIBAv+YwM8LuGo/5gvhx+gxcRgZXPf4KX80ZRPSuGaxddJYO\nsVP9mkmkLMjXMSHOufeA934ybXKe213P831rgJaXElBESreggCAeve5RqpWrRtzmOI6cOcKTNzxJ\ncGCw37PUGD0a8wVz8OmnITOTq6cuJ37uEDokzmHdggzaD52GBegajyKFpVAPTBUR+SXMjHvb3stl\n5S5jWsI0jqUfY3qn6VQKruT3LNWHDcV8Pg785S+49Ptp9cxivpw/nOg9C1k7P4PoETNUREQKiV5J\nIlJsDG4xmMevf5yE/QnErIph/6n9nuS4LGYQtR95hJOffca+CXfTZsQC1lfvT4d9S1k/ZzQuO9uT\nXCKljUqIiBQr/Rr3Y3aX2ew7uY/fvfs7tqRu8SRHtYG3U+eJJzi1Zg0pY8cRFfs862reRvTBV/ly\n9jCys7I8ySVSmqiEiEixc12961jaaym+AB+xq2I9u8x71d/cSt2pT3E6Pp7k0aOJGvQMa+vcSftD\nb5AwK0ZFROQSqYSISLHUpFoTXuzzIo1CG3HPJ/ewZMsST07hDe3bl3rTnibtmw3sGT6Cdrc/wbr6\nw7j2yDt8NXMgWZmZfs8kUlqohIhIsVWjfA3iesbRNbIr0xKmMel/J5GWmeb3HFV696be9GdJ27qV\n5GHDaTdgMmsjR9Pu2AdsmPFbMtLPXnwhIvIzKiEiUqyVDyrPtBunMa7VON7d/S6D3x9MysmfXbS5\nyFXp1o36M2dw9rvvSBwSS7v+D7Du8gm0PfExm2YMIP3sGb9nEinpVEJEpNgLsABGXzOa5256juQT\nyQx8ZyDr9q3ze47KnTtT/4UXSP/+e5JiYojqfTfrmv6eNqc+Z+uM/pw9c/riCxGR/1AJEZES48bw\nG3m5z8tUL1edUR+OYuGmhWQ7/54uW6nj9YTPnUP6nhQSB8XQtsso1jebRKvTa9k+vS9nTp/0ax6R\nkkwlRERKlAahDXixz4t0jejK9K+nM/ajsaSmpfo1Q8XoaCLmzyPzwAESYwbR5lcxfNnyEa5KS2Dn\njD6knTrh1zwiJZVKiIiUOBV9FZl24zQejn6Y+P3xDHh7AOv3rfdrhgpRUYQvXEBW6mES7xxEq/a3\n8VXrJ2h25l/sntGLUyeO+jWPSEmkEiIiJZKZcdsVt/FSn5eoHFyZER+M4LlvniMjO8NvGSq0bk3E\nokVknTxJ4qBBXNP613zT7q9ccXYLyTN7cfyof/fQiJQ0KiEiUqJdcdkVvNLnFfo26su8jfMY9N4g\ndh3d5bf1l295FZGLF+HS0kgcFEPL5l3Z2OFZGqVvZ/+snhw7/KPfsoiUNCohIlLiVfBV4PGOjzPt\nxmmknEzhtrdvY8mWJWRl++eKpuWaNSNi6RJcVhaJMYNpfvl1bOk4iwYZu/nx+R4cPeTNZ+CIFHcq\nISJSavRo0IMV/VZwXb3rmJYwjdjVsSQdT/LLuss1bUrksqWYGUmDh3BleBu2dZpDeGYSR2b3IPXA\nHr/kEClJVEJEpFSpUb4GMzvP5ImOT7DzyE5uXXkr8zfOJyOr6I8VCbn88pwiEhJC4uAhNA1rzndd\nFlI7ay8n5/bk0N7EIs8gUpKohIhIqWNm9G3UlxX9VvCr+r9i5jczGfD2ABL2JxT5uoMbNCBy+TIC\nK1UiKTaWxlUi2d1jCWFZB0mb35ODKd8XeQaRkkIlRERKrVoVa/FMp2d4vsvznMk8Q+zqWB7+v4c5\nfOZwka43uH59IpctJbBaNZKGDqNhSC2Sei+nWvYRMhb0YF/i9iJdv0hJoRIiIqXer+r/ihX9VjD0\nqqG8s+sd+rzRh4WbFnI2q+g+eM5Xty6Ry5YRVKsWScNHEO5C2dvvFSq7E9iiPqTs3lZk6xYpKVRC\nRKRMqOCrwL1t7+X1fq8TVSuK6V9Pp++Kvqz6fhXOuSJZp69WTSKXLsFXry7Jo0ZR97SPg7f8nXKk\n4Vvam+Qd/yqS9YqUFCohIlKmXB56Oc91eY753edTObgyf/j8D9z53p2sSVlTJGUkKCyMyKVLCW7Q\ngD1jx1L7aBaHB7xBEJmUf7Evidu+KvR1ipQUKiEiUiZF14nm1V+/ypTrpnAw7SCjPhpFzPsxrNlb\n+GUk6LLLiFi8iJDGjUkefxdh+09w4vY3Aaj8an92b/bvJedFigsrqt2QlyIqKsolJBT9UewiIgDp\nWem8ufNN5m2cx4HTB2hdszUjWo7g+nrXE2CF97da1vHjJI0YwZktW6k37WmONapDyIv9CSadQ7e8\nRuNrri+0dYkUJ2b2lXMu6mfTVUJERHKkZ6WzYscK5m+az4HTB2gY2pBBzQdx8+U3Uy6oXKGsI+vk\nSZJHjiJtwwbqTp3KyRYNCVzajwqcZn/fl2japlOhrEekOFEJERHJp4ysDFb9sIplW5ex7fA2qoZU\n5bdNf8uApgOoW6nuJS8/+9QpkseM5XR8PHWeeIK0ts1xi2+mSvZx9vRZxpXXdiuEZyFSfKiEiIgU\nkHOOhAMJLNu6jE+TPwVyjiW5pckt3BRxEyGBIb942dlpaewZN55Ta9ZQ+9FHSb++LekLf0317FS+\n77GYFtf1LqRnIeI9lRARkUuw9+Re3tr5Fm/ufJO9p/ZSObgyvRr0oluDbkTViiIoIKjAy8w+e5aU\nCXdz8rPPCLvnHtzNPTi98NfUzDrAzi4LaPmrfkXwTET8TyVERKQQZLtsvtz/JW/seINPkz8lLTON\nqiFV6Rzema6RXWlfp32B9pC49HT2PvQnjr/9NqH9+xM8bgQnFt1C3awUtneaw9WdBxThsxHxD5UQ\nEZFClpaZxpqUNXyY9CGfJX/GyYyThASG0Lpma6LrRBNdN5orq11JYEDgBZfjnOPQ7Nkcem4WFaKi\nqPzonzj80h1EZCay9YZZtOp6h5+ekUjRuKQSYmY9gRlAILDAOffUTx4PAZYCbYFU4Hbn3A+5jz0I\nDAOygAnOudUXW59KiIiUNOlZ6azft561+9aybt86dhzZAUDl4Mq0qN6Cq2pcxVXVr6JFjRbUqlAL\nM/vZMo698y77Jk0iqE5tqj75BIffG0PDjF1s6vAMbXoO8fMzEik8v7iEmFkg8B3QDdgDxAN3OOe2\n5plnLHC1c260mQ0EbnHO3W5mzYGXgWuBusBHQFPnXNaF1qkSIiIl3aG0Q6zft574/fFsSd3CjiM7\nyMr90RcaEkpk5Ugiq+R8RVSJIKx8GNXLV6fSt3s4cu8DZB05gq9FczKCdhFRcw/buj1O1M2jPH5W\nIr/MpZSQDsAjzrkeufcfBHDOPZlnntW586w1syBgPxAGPJB33rzzXWidKiEiUtqcyTzD9iPb2Xxo\nM7uP7ibxeCI/HP+BA6cP/GzeWicD6bEpiKt3ZBCRkg7A8UqOo5V1kWspOkfrVeL25V8WybLPV0Ly\nczh3PSA5z/09QPvzzeOcyzSzY0D13OnrfvK99c4TcCQwEiAiIiIfsURESo5yQeW4Juwargm75r+m\np2WmkXwimdS0VFLPpHI47TCpZ1I53uY4n2elE3j4OLU27KHWV7spdybTo/RSFjifz+/rLPg5ZUXE\nOTcPmAc5e0I8jiMi4hflg8rTtFpTqHaBmfr6LY6IX+Vn314KEJ7nfv3caeecJ/ftmFByDlDNz/eK\niIhIGZSfEhIPNDGzhmYWDAwEVv5knpXA4NzbA4CPXc7BJiuBgWYWYmYNgSZA0bzhJCIiIiXKRd+O\nyT3GYzywmpxTdOOcc1vMbAqQ4JxbCSwElpnZTuAwOUWF3PleA7YCmcC4i50ZIyIiImWDLlYmIiIi\nRep8Z8fofC8RERHxhEqIiIiIeEIlRERERDyhEiIiIiKeUAkRERERT6iEiIiIiCdUQkRERMQTKiEi\nIiLiCZUQERER8USxvGKqmf0IJBbBomsAh4pguaWVxqvgNGYFo/EqGI1XwWi8CqYoxyvSORf204nF\nsoQUFTNLONdlY+XcNF4FpzErGI1XwWi8CkbjVTBejJfejhERERFPqISIiIiIJ8paCZnndYASRuNV\ncBqzgtF4FYzGq2A0XgXj9/EqU8eEiIiISPFR1vaEiIiISDFRqkuImf3WzLaYWbaZnfeIXzPraWbb\nzWynmT3gz4zFiZldZmYfmtmO3H+rnWe+LDPbkPu10t85vXax7cXMQszs1dzH15tZA/+nLD7yMV5D\nzOzHPNvUcC9yFhdmFmdmB81s83keNzObmTueG82sjb8zFif5GK9OZnYsz/Y12d8ZixMzCzezT8xs\na+7vx7vPMY/ftrFSXUKAzcCtwOfnm8HMAoHngV5Ac+AOM2vun3jFzgPAP51zTYB/5t4/lzTnXKvc\nr77+i+e9fG4vw4AjzrnGwLPAVP+mLD4K8Pp6Nc82tcCvIYufxUDPCzzeC2iS+zUSeMEPmYqzxVx4\nvAC+yLN9TfFDpuIsE7jfOdcciAbGneM16bdtrFSXEOfcNufc9ovMdi2w0zm32zmXDrwC9Cv6dMVS\nP2BJ7u0lQH8PsxRX+dle8o7jP4AuZmZ+zFic6PVVQM65z4HDF5ilH7DU5VgHVDWzOv5JV/zkY7wk\nD+fcPufc17m3TwDbgHo/mc1v21ipLiH5VA9IznN/Dz//Dykrajnn9uXe3g/UOs985cwswczWmVlZ\nKyr52V7+M49zLhM4BlT3S7riJ7+vr9/k7vb9h5mF+ydaiaWfWQXXwcz+ZWbvm1kLr8MUF7lvFbcG\n1v/kIb9tY0FFsVB/MrOPgNrneOgh59xb/s5T3F1ovPLecc45MzvfqVORzrkUM7sc+NjMNjnndhV2\nVikz3gZeds6dNbNR5OxFusnjTFJ6fE3Oz6yTZtYbeJOctxnKNDOrBLwO3OOcO+5VjhJfQpxzXS9x\nESlA3r+86udOK5UuNF5mdsDM6jjn9uXuejt4nmWk5P6728w+JadJl5USkp/t5d/z7DGzICAUSPVP\nvGLnouPlnMs7NguAv/ohV0lWpn5mXaq8v2Cdc++Z2Wwzq+GcK7OfKWNmPnIKyIvOuTfOMYvftjG9\nHQPxQBMza2hmwcBAoMyd8ZFrJTA49/Zg4Gd7ksysmpmF5N6uAVwPbPVbQu/lZ3vJO44DgI9d2b0g\nz0XH6yfvNfcl5z1qOb+VQEzuGQzRwLE8b6PKT5hZ7X8fk2Vm15Lze6+s/lFA7lgsBLY55545z2x+\n28ZK/J6QCzGzW4DngDDgXTPb4JzrYWZ1gQXOud7OuUwzGw+sBgKBOOfcFg9je+kp4DUzG0bOpxjf\nBmA5pzePds4NB5oBc80sm5wX81POuTJTQs63vZjZFCDBObeSnBf4MjPbSc4BcwO9S+ytfI7XBDPr\nS85R+4eBIZ4FLgbM7GWgE1DDzPYAfwZ8AM65OcB7QG9gJ3AaiPUmafGQj/EaAIwxs0wgDRhYhv8o\ngJw/HAcBm8xsQ+60SUAE+H8b0xVTRURExBN6O0ZEREQ8oRIiIiIinlAJEREREU+ohIiIiIgnVEJE\nRETEEyohIiIi4gmVEBEREfGESoiIiIh44v8BOUkJfztp5G8AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 648x432 with 1 Axes>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "less_smooth = hinge_rep.smoothed(rr.identity_quadratic(5.e-2, 0, 0, 0))\n",
    "ax.plot(r, [less_smooth.smooth_objective(v, 'func') for v in r])\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fitting the SVM\n",
    "\n",
    "We can now minimize this objective."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "smoothed_vec = hinge_vec.smoothed(rr.identity_quadratic(0.2, 0, 0, 0))\n",
    "soln = smoothed_vec.solve(tol=1.e-12, min_its=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sparse SVM\n",
    "\n",
    "We might want to fit a sparse version, adding a sparsifying penalty like\n",
    "the LASSO. This yields the problem\n",
    "\n",
    "$$\n",
    "\\text{minimize}_{\\beta} \\ell(\\beta) + \\lambda \\|\\beta\\|_1\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$$\n",
       "\\begin{aligned}\n",
       "\\text{minimize}_{\\beta} & f(\\beta) + g(\\beta) \\\\\n",
       "f(\\beta) &=  \\sup_{u \\in \\mathbb{R}^{p} } \\left[ \\langle X_{1}\\beta, u \\rangle - \\left(I^{\\infty}(\\left\\|u\\right\\|_{\\infty} + I^{\\infty}\\left(\\min(u) \\in [0,+\\infty)\\right)  \\leq \\delta_{1}) + \\frac{L_{1}}{2}\\|u\\|^2_2 + \\left \\langle \\eta_{1}, u \\right \\rangle \\right) \\right] \\\\\n",
       "g(\\beta) &= \\lambda_{2} \\|\\beta\\|_1 \\\\\n",
       "\\end{aligned}\n",
       "$$"
      ],
      "text/plain": [
       "<regreg.problems.simple.simple_problem at 0x121957898>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "penalty = rr.l1norm(smoothed_vec.shape, lagrange=20)\n",
    "problem = rr.simple_problem(smoothed_vec, penalty)\n",
    "problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{aligned}\n",
    "\\text{minimize}_{\\beta} & f(\\beta) + g(\\beta) \\\\\n",
    "f(\\beta) &=  \\sup_{u \\in \\mathbb{R}^{p} } \\left[ \\langle X_{1}\\beta, u \\rangle - \\left(I^{\\infty}(\\left\\|u\\right\\|_{\\infty} + I^{\\infty}\\left(\\min(u) \\in [0,+\\infty)\\right)  \\leq \\delta_{1}) + \\frac{L_{1}}{2}\\|u\\|^2_2 + \\left \\langle \\eta_{1}, u \\right \\rangle \\right) \\right] \\\\\n",
    "g(\\beta) &= \\lambda_{2} \\|\\beta\\|_1 \\\\\n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.11794475,  0.08667502,  0.        , -0.0634286 ,  0.04145064,\n",
       "        0.        ,  0.12536322, -0.        ,  0.        , -0.09668681,\n",
       "        0.05306269,  0.        , -0.01064823, -0.        ,  0.0377666 ,\n",
       "        0.        , -0.08346559, -0.1200484 ,  0.        , -0.00345114,\n",
       "        0.        , -0.        , -0.        , -0.02736643,  0.01014732,\n",
       "       -0.0830704 ,  0.        ,  0.        , -0.05251217, -0.        ,\n",
       "        0.03145735, -0.01476226,  0.        ,  0.04094988, -0.09225357,\n",
       "        0.16668443, -0.0068806 ,  0.        , -0.06944853, -0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.06859081,  0.        ,\n",
       "       -0.        , -0.02868384, -0.        ,  0.05566649,  0.        ,\n",
       "       -0.        , -0.        , -0.06390489, -0.        ,  0.        ,\n",
       "       -0.13076543,  0.        ,  0.05820014, -0.03504912, -0.        ,\n",
       "        0.00298815,  0.06577031,  0.        ,  0.        , -0.02236921,\n",
       "        0.        , -0.        , -0.        ,  0.00310002, -0.        ,\n",
       "        0.        ,  0.03470329,  0.12713361,  0.        ,  0.        ,\n",
       "       -0.00590934,  0.09227397, -0.        ,  0.        , -0.        ,\n",
       "       -0.        , -0.        , -0.08209436,  0.        ,  0.        ,\n",
       "       -0.        , -0.        ,  0.        ,  0.        ,  0.00291966,\n",
       "       -0.        ,  0.        ,  0.        ,  0.        ,  0.0123154 ,\n",
       "       -0.        , -0.        , -0.        ,  0.        ,  0.05862961,\n",
       "        0.00557241, -0.        ,  0.        ,  0.04873143, -0.07727929,\n",
       "       -0.08051248, -0.0108722 ,  0.        ,  0.        , -0.12305824,\n",
       "        0.02206252,  0.0209065 ,  0.        ,  0.05100838, -0.        ,\n",
       "        0.04406697,  0.00463305, -0.        ,  0.        , -0.07109647,\n",
       "       -0.02693662,  0.        ,  0.        , -0.        ,  0.10813817,\n",
       "       -0.00420924, -0.09335061, -0.1076696 , -0.        ,  0.        ,\n",
       "       -0.00132466,  0.11999136,  0.        , -0.10466986,  0.        ,\n",
       "        0.        , -0.00742986,  0.14161097,  0.        , -0.        ,\n",
       "        0.        , -0.0744488 ,  0.        ,  0.05240747, -0.        ,\n",
       "       -0.        ,  0.        , -0.05325711, -0.        , -0.00335929,\n",
       "       -0.        ,  0.02508744, -0.02740809, -0.        , -0.05282792,\n",
       "        0.        , -0.1025743 , -0.        ,  0.        ,  0.09375117,\n",
       "       -0.19386661,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.0172358 , -0.06139685,  0.        ,  0.        ,  0.        ,\n",
       "       -0.        , -0.01383084,  0.        , -0.00907931,  0.        ,\n",
       "       -0.06658488, -0.00588045,  0.        ,  0.03005927, -0.13127342,\n",
       "        0.01499859, -0.11638599,  0.        , -0.07997269,  0.00033085,\n",
       "       -0.05006203, -0.03970144, -0.        ,  0.        ,  0.04083319,\n",
       "       -0.11504934, -0.10957298,  0.        ,  0.        , -0.05774499,\n",
       "       -0.        , -0.        ,  0.        , -0.0003005 ,  0.        ])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sparse_soln = problem.solve(tol=1.e-12)\n",
    "sparse_soln"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What value of $\\lambda$ should we use? For the $\\ell_1$\n",
    "penalty in Lagrange form, the smallest $\\lambda$ such that the\n",
    "solution is zero can be found by taking the dual norm, the\n",
    "$\\ell_{\\infty}$ norm, of the gradient of the smooth part at 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$$I^{\\infty}(\\|\\beta\\|_{\\infty} \\leq \\delta_{})$$"
      ],
      "text/plain": [
       "supnorm((200,), bound=20.000000, offset=None)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linf_norm = penalty.conjugate\n",
    "linf_norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "I^{\\infty}(\\|\\beta\\|_{\\infty} \\leq \\delta_{})\n",
    "$$\n",
    "\n",
    "Just computing the conjugate will yield an $\\ell_{\\infty}$\n",
    "constraint, but this object can still be used to compute the desired\n",
    "value of $\\lambda$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "90.06739154192712"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_at_zero = smoothed_vec.smooth_objective(np.zeros(smoothed_vec.shape), 'grad')\n",
    "lam_max = linf_norm.seminorm(score_at_zero, lagrange=1.)\n",
    "lam_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.,  0., -0., -0.,  0.,  0.,  0., -0.,  0., -0.,  0., -0., -0.,\n",
       "        0.,  0., -0., -0., -0., -0., -0.,  0.,  0., -0., -0.,  0., -0.,\n",
       "        0.,  0., -0., -0.,  0., -0., -0.,  0., -0.,  0., -0.,  0., -0.,\n",
       "       -0., -0.,  0., -0.,  0.,  0.,  0., -0.,  0.,  0.,  0., -0., -0.,\n",
       "       -0., -0., -0., -0., -0.,  0., -0., -0.,  0.,  0.,  0.,  0., -0.,\n",
       "       -0., -0., -0.,  0., -0.,  0.,  0.,  0.,  0.,  0., -0.,  0., -0.,\n",
       "        0., -0., -0., -0., -0.,  0.,  0., -0., -0.,  0.,  0.,  0., -0.,\n",
       "        0., -0.,  0.,  0.,  0., -0., -0.,  0.,  0.,  0., -0., -0.,  0.,\n",
       "       -0., -0., -0.,  0.,  0., -0.,  0.,  0.,  0.,  0., -0.,  0.,  0.,\n",
       "       -0.,  0., -0., -0.,  0., -0., -0.,  0., -0., -0., -0., -0.,  0.,\n",
       "       -0.,  0., -0., -0.,  0.,  0., -0.,  0.,  0., -0., -0., -0.,  0.,\n",
       "        0., -0.,  0.,  0., -0., -0., -0., -0.,  0., -0., -0., -0., -0.,\n",
       "       -0., -0.,  0.,  0., -0.,  0.,  0.,  0., -0.,  0., -0.,  0.,  0.,\n",
       "        0., -0., -0.,  0., -0.,  0., -0., -0.,  0.,  0., -0.,  0., -0.,\n",
       "        0., -0.,  0., -0., -0., -0.,  0.,  0., -0., -0.,  0.,  0., -0.,\n",
       "        0.,  0.,  0., -0.,  0.])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "penalty.lagrange = lam_max * 1.001\n",
    "problem.solve(tol=1.e-12, min_its=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.        ,  0.        , -0.        , -0.        ,  0.        ,\n",
       "        0.        ,  0.        , -0.        ,  0.        , -0.        ,\n",
       "        0.        , -0.        , -0.        ,  0.        ,  0.        ,\n",
       "       -0.        , -0.        , -0.        , -0.        , -0.        ,\n",
       "        0.        ,  0.        , -0.        , -0.        ,  0.        ,\n",
       "       -0.        ,  0.        ,  0.        , -0.        , -0.        ,\n",
       "        0.        , -0.        , -0.        ,  0.        , -0.        ,\n",
       "        0.        , -0.        ,  0.        , -0.        , -0.        ,\n",
       "       -0.        ,  0.        , -0.        ,  0.        ,  0.        ,\n",
       "        0.        , -0.        ,  0.        ,  0.        ,  0.        ,\n",
       "       -0.        , -0.        , -0.        , -0.        , -0.        ,\n",
       "       -0.        , -0.        ,  0.        , -0.        , -0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        , -0.        ,\n",
       "       -0.        , -0.        , -0.        ,  0.        , -0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "       -0.        ,  0.        , -0.        ,  0.        , -0.        ,\n",
       "       -0.        , -0.        , -0.        ,  0.        ,  0.        ,\n",
       "       -0.        , -0.        ,  0.        ,  0.        ,  0.        ,\n",
       "       -0.        ,  0.        , -0.        ,  0.        ,  0.        ,\n",
       "        0.        , -0.        , -0.        ,  0.        ,  0.        ,\n",
       "        0.        , -0.        , -0.        ,  0.        , -0.        ,\n",
       "       -0.        , -0.        ,  0.        ,  0.        , -0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        , -0.        ,\n",
       "        0.        ,  0.        , -0.        ,  0.        , -0.        ,\n",
       "       -0.        ,  0.        , -0.        , -0.        ,  0.        ,\n",
       "       -0.        , -0.        , -0.        , -0.        ,  0.        ,\n",
       "       -0.        ,  0.        , -0.        , -0.        ,  0.        ,\n",
       "        0.        , -0.        ,  0.        ,  0.        , -0.        ,\n",
       "       -0.        , -0.        ,  0.        ,  0.        , -0.        ,\n",
       "        0.        ,  0.        , -0.        , -0.        , -0.        ,\n",
       "       -0.        ,  0.        , -0.        , -0.        , -0.        ,\n",
       "       -0.        , -0.        , -0.        ,  0.        ,  0.        ,\n",
       "       -0.25288433,  0.        ,  0.        ,  0.        , -0.        ,\n",
       "        0.        , -0.        , -0.        ,  0.        ,  0.        ,\n",
       "       -0.        , -0.        ,  0.        , -0.        ,  0.        ,\n",
       "       -0.        , -0.        ,  0.        ,  0.        , -0.        ,\n",
       "        0.        , -0.        ,  0.        , -0.        ,  0.        ,\n",
       "       -0.        , -0.        , -0.        ,  0.        ,  0.        ,\n",
       "       -0.        , -0.        ,  0.        ,  0.        , -0.        ,\n",
       "        0.        ,  0.        ,  0.        , -0.        ,  0.        ])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "penalty.lagrange = lam_max * 0.99\n",
    "problem.solve(tol=1.e-12, min_its=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Path of solutions\n",
    "\n",
    "If we want a path of solutions, we can simply take multiples of\n",
    "`lam_max`. This is similar to the strategy that packages like\n",
    "`glmnet` use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = []\n",
    "lam_vals = (np.linspace(0.05, 1.01, 50) * lam_max)[::-1]\n",
    "for lam_val in lam_vals:\n",
    "    penalty.lagrange = lam_val\n",
    "    path.append(problem.solve(min_its=200).copy())\n",
    "fig = plt.figure(figsize=(12,8))\n",
    "ax = fig.gca()\n",
    "path = np.array(path)\n",
    "ax.plot(path);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Changing the penalty\n",
    "\n",
    "We may not want to penalize features the same. We may want some features\n",
    "to be unpenalized. This can be achieved by introducing possibly non-zero\n",
    "feature weights to the $\\ell_1$ norm\n",
    "\n",
    "$$\n",
    "\\beta \\mapsto \\sum_{j=1}^p w_j|\\beta_j|\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$$\\lambda_{} \\|W\\beta\\|_1$$"
      ],
      "text/plain": [
       "l1norm([0.         0.         0.         0.         0.         1.87296458\n",
       " 1.18891642 1.91698625 1.70801345 1.57996509 1.08922197 1.83593569\n",
       " 1.10172778 1.95641938 1.71838292 1.66352323 1.70349313 1.80109366\n",
       " 1.25404202 1.25903633 1.65460983 1.6920795  1.41797663 1.92520815\n",
       " 1.7335934  1.29442753 1.44168013 1.60128268 1.66240986 1.16660547\n",
       " 1.27271487 1.00144935 1.52929368 1.25449996 1.19666245 1.77042046\n",
       " 1.8229748  1.47209586 1.14098216 1.77038834 1.03449807 1.79150344\n",
       " 1.12021593 1.59620413 1.16008248 1.52955354 1.5361846  1.84017027\n",
       " 1.69099274 1.72173419 1.63190979 1.04230409 1.99959201 1.1458063\n",
       " 1.75472996 1.44436963 1.17142941 1.41738061 1.0372572  1.45189326\n",
       " 1.26096963 1.80290619 1.5144726  1.78357967 1.49870195 1.81307546\n",
       " 1.42599743 1.8702529  1.36186565 1.12848694 1.61653581 1.2054714\n",
       " 1.29042584 1.67678491 1.25786305 1.05517905 1.19010324 1.48372219\n",
       " 1.93900183 1.51204541 1.79871647 1.39977394 1.34848333 1.38318479\n",
       " 1.88176022 1.50036102 1.55659098 1.64742839 1.09221121 1.68319653\n",
       " 1.66184415 1.01461985 1.28655637 1.49607169 1.6651781  1.08469433\n",
       " 1.34185327 1.39905373 1.52923108 1.60075428 1.04987568 1.34219995\n",
       " 1.09679974 1.2448212  1.11402305 1.20058077 1.15406651 1.68017224\n",
       " 1.00409859 1.29742231 1.45471301 1.87166352 1.9113602  1.41554371\n",
       " 1.07186285 1.93027428 1.55599441 1.27159961 1.34832678 1.22285305\n",
       " 1.48721868 1.89474621 1.68320802 1.13343124 1.75167968 1.51324\n",
       " 1.61231264 1.04464657 1.0119143  1.88908859 1.60880355 1.30845234\n",
       " 1.54563343 1.11150093 1.18470559 1.68569635 1.54448152 1.29167077\n",
       " 1.47906838 1.92328934 1.56755271 1.50680326 1.32593101 1.07949459\n",
       " 1.27494446 1.83536675 1.64533382 1.58360528 1.21259956 1.00372708\n",
       " 1.18756043 1.64597364 1.10947498 1.04607914 1.76306777 1.21024178\n",
       " 1.96789988 1.71197462 1.55198414 1.49410367 1.66192441 1.52064849\n",
       " 1.81301853 1.32968657 1.65466259 1.83444705 1.33136711 1.92498438\n",
       " 1.64212022 1.09542385 1.55364069 1.54028077 1.44249832 1.02330522\n",
       " 1.52276395 1.21313977 1.01238264 1.52622176 1.58362862 1.29791821\n",
       " 1.18449863 1.20629252 1.86270807 1.47676334 1.77096636 1.6468548\n",
       " 1.39530309 1.84052028 1.77438504 1.71437471 1.01895186 1.54508697\n",
       " 1.45210867 1.44212817 1.56691066 1.05774286 1.21836888 1.50234326\n",
       " 1.2819072  1.92155648], lagrange=1.000000, offset=None, quadratic=identity_quadratic(0.000000, 0.0, 0.0, 0.000000))"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights = np.random.sample(P) + 1.\n",
    "weights[:5] = 0.\n",
    "weighted_penalty = rr.weighted_l1norm(weights, lagrange=1.)\n",
    "weighted_penalty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\lambda_{} \\|W\\beta\\|_1\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$$I^{\\infty}(\\|W\\beta\\|_{\\infty} \\leq \\delta_{})$$"
      ],
      "text/plain": [
       "supnorm([       inf        inf        inf        inf        inf 0.53391293\n",
       " 0.84110202 0.52165215 0.58547548 0.63292538 0.91808651 0.54468139\n",
       " 0.90766523 0.51113785 0.58194247 0.60113378 0.58702908 0.55521821\n",
       " 0.79742144 0.79425825 0.60437209 0.59098878 0.70523024 0.51942435\n",
       " 0.57683653 0.77254228 0.69363514 0.62449935 0.60153637 0.85718782\n",
       " 0.78572194 0.99855275 0.65389664 0.79713036 0.83565754 0.56483757\n",
       " 0.54855393 0.67930359 0.87643789 0.56484782 0.96665236 0.55819039\n",
       " 0.89268504 0.62648629 0.86200767 0.65378555 0.65096343 0.54342797\n",
       " 0.59136859 0.58080975 0.61277897 0.95941291 0.50010202 0.87274787\n",
       " 0.56988826 0.69234355 0.85365792 0.7055268  0.96408104 0.68875587\n",
       " 0.79304051 0.55466003 0.66029587 0.56067022 0.66724408 0.55154902\n",
       " 0.70126354 0.53468705 0.73428682 0.88614229 0.61860677 0.829551\n",
       " 0.77493799 0.59637941 0.7949991  0.94770646 0.84026323 0.67398062\n",
       " 0.51572927 0.6613558  0.55595199 0.71440107 0.74157387 0.7229692\n",
       " 0.53141733 0.66650625 0.64242952 0.60700666 0.91557383 0.59410769\n",
       " 0.60174114 0.98559081 0.7772687  0.66841716 0.60053636 0.92191871\n",
       " 0.74523797 0.71476883 0.65392341 0.6247055  0.95249373 0.74504548\n",
       " 0.91174347 0.80332822 0.89764749 0.83293021 0.86650118 0.59517708\n",
       " 0.99591814 0.77075906 0.68742081 0.53428407 0.52318762 0.70644233\n",
       " 0.93295518 0.51806109 0.64267583 0.78641106 0.74165997 0.81775975\n",
       " 0.67239607 0.52777517 0.59410363 0.88227672 0.57088063 0.66083371\n",
       " 0.62022711 0.95726155 0.98822598 0.5293558  0.62157993 0.76426169\n",
       " 0.64698394 0.89968436 0.84409157 0.59322665 0.64746647 0.77419109\n",
       " 0.67610126 0.51994257 0.63793708 0.66365665 0.75418705 0.92635944\n",
       " 0.78434789 0.54485023 0.6077794  0.63147049 0.82467455 0.99628676\n",
       " 0.84206241 0.60754314 0.90132722 0.95595062 0.56719317 0.82628118\n",
       " 0.50815593 0.58412081 0.64433648 0.6692976  0.60171209 0.65761417\n",
       " 0.55156634 0.75205693 0.60435282 0.54512339 0.75110763 0.51948473\n",
       " 0.60896881 0.91288865 0.64364947 0.64923228 0.69324171 0.97722555\n",
       " 0.6567006  0.82430733 0.98776882 0.65521278 0.63146118 0.77046457\n",
       " 0.84423905 0.82898632 0.53685278 0.67715657 0.56466346 0.60721808\n",
       " 0.71669016 0.54332463 0.56357554 0.58330305 0.98140064 0.64721276\n",
       " 0.6886537  0.69341964 0.63819848 0.94540936 0.82076949 0.66562684\n",
       " 0.78008767 0.52041145], bound=1.000000, offset=None, quadratic=identity_quadratic(0.000000, 0.0, 0.0, 0.000000))"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weighted_dual = weighted_penalty.conjugate\n",
    "weighted_dual"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "I^{\\infty}(\\|W\\beta\\|_{\\infty} \\leq \\delta_{})\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "67.27348860880447"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lam_max_weight = weighted_dual.seminorm(score_at_zero, lagrange=1.)\n",
    "lam_max_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "weighted_problem = rr.simple_problem(smoothed_vec, weighted_penalty)\n",
    "path = []\n",
    "lam_vals = (np.linspace(0.05, 1.01, 50) * lam_max_weight)[::-1]\n",
    "for lam_val in lam_vals:\n",
    "    weighted_penalty.lagrange = lam_val\n",
    "    path.append(weighted_problem.solve(min_its=200).copy())\n",
    "fig = plt.figure(figsize=(12,8))\n",
    "ax = fig.gca()\n",
    "path = np.array(path)\n",
    "ax.plot(path);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that there are 5 coefficients that are not penalized hence they are\n",
    "nonzero the entire path.\n",
    "\n",
    "Variables may come in groups. A common penalty for this setting is the\n",
    "group LASSO. Let\n",
    "\n",
    "$$\n",
    "\\{1, \\dots, p\\} = \\cup_{g \\in G} g\n",
    "$$\n",
    "\n",
    "be a partition of the set of features and $w_g$ a weight for each\n",
    "group. The group LASSO penalty is\n",
    "\n",
    "$$\n",
    "\\beta \\mapsto \\sum_{g \\in G} w_g \\|\\beta_g\\|_2.\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = []\n",
    "for i in range(int(P/5)):\n",
    "    groups.extend([i]*5)\n",
    "weights = dict([g, np.random.sample()+1] for g in np.unique(groups))\n",
    "group_penalty = rr.group_lasso(groups, weights=weights, lagrange=1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_dual = group_penalty.conjugate\n",
    "lam_max_group = group_dual.seminorm(score_at_zero, lagrange=1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_problem = rr.simple_problem(smoothed_vec, group_penalty)\n",
    "path = []\n",
    "lam_vals = (np.linspace(0.05, 1.01, 50) * lam_max_group)[::-1]\n",
    "for lam_val in lam_vals:\n",
    "    group_penalty.lagrange = lam_val\n",
    "    path.append(group_problem.solve(min_its=200).copy())\n",
    "fig = plt.figure(figsize=(12,8))\n",
    "ax = fig.gca()\n",
    "path = np.array(path)\n",
    "ax.plot(path);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, variables enter in groups here.\n",
    "\n",
    "## Bound form\n",
    "\n",
    "The common norm atoms also have a bound form. That is, we can just as\n",
    "easily solve the problem\n",
    "\n",
    "$$\n",
    "\\text{minimize}_{\\beta: \\|\\beta\\|_1 \\leq \\delta}\\ell(\\beta)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$$I^{\\infty}(\\|\\beta\\|_1 \\leq \\delta_{})$$"
      ],
      "text/plain": [
       "l1norm((200,), bound=2.000000, offset=None)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bound_l1 = rr.l1norm(P, bound=2.)\n",
    "bound_l1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "I^{\\infty}(\\|\\beta\\|_1 \\leq \\delta_{})\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$$\n",
       "\\begin{aligned}\n",
       "\\text{minimize}_{\\beta} & f(\\beta) + g(\\beta) \\\\\n",
       "f(\\beta) &=  \\sup_{u \\in \\mathbb{R}^{p} } \\left[ \\langle X_{1}\\beta, u \\rangle - \\left(I^{\\infty}(\\left\\|u\\right\\|_{\\infty} + I^{\\infty}\\left(\\min(u) \\in [0,+\\infty)\\right)  \\leq \\delta_{1}) + \\frac{L_{1}}{2}\\|u\\|^2_2 + \\left \\langle \\eta_{1}, u \\right \\rangle \\right) \\right] \\\\\n",
       "g(\\beta) &= I^{\\infty}(\\|\\beta\\|_1 \\leq \\delta_{2}) \\\\\n",
       "\\end{aligned}\n",
       "$$"
      ],
      "text/plain": [
       "<regreg.problems.simple.simple_problem at 0x124182320>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bound_problem = rr.simple_problem(smoothed_vec, bound_l1)\n",
    "bound_problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{aligned}\n",
    "\\text{minimize}_{\\beta} & f(\\beta) + g(\\beta) \\\\\n",
    "f(\\beta) &=  \\sup_{u \\in \\mathbb{R}^{p} } \\left[ \\langle X_{1}\\beta, u \\rangle - \\left(I^{\\infty}(\\left\\|u\\right\\|_{\\infty} + I^{\\infty}\\left(\\min(u) \\in [0,+\\infty)\\right)  \\leq \\delta_{1}) + \\frac{L_{1}}{2}\\|u\\|^2_2 + \\left \\langle \\eta_{1}, u \\right \\rangle \\right) \\right] \\\\\n",
    "g(\\beta) &= I^{\\infty}(\\|\\beta\\|_1 \\leq \\delta_{2}) \\\\\n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0000000000000004"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bound_soln = bound_problem.solve()\n",
    "np.fabs(bound_soln).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Support vector machine\n",
    "\n",
    "This tutorial illustrates one version of the support vector machine, a\n",
    "linear example. The minimization problem for the support vector machine,\n",
    "following *ESL* is\n",
    "\n",
    "$$\n",
    "\\text{minimize}_{\\beta,\\gamma} \\sum_{i=1}^n (1- y_i(x_i^T\\beta+\\gamma))^+ + \\frac{\\lambda}{2} \\|\\beta\\|^2_2\n",
    "$$\n",
    "\n",
    "We use the $C$ parameterization in (12.25) of *ESL*\n",
    "\n",
    "$$\n",
    "\\text{minimize}_{\\beta,\\gamma} C \\sum_{i=1}^n (1- y_i(x_i^T\\beta+\\gamma))^+  + \\frac{1}{2} \\|\\beta\\|^2_2\n",
    "$$\n",
    "\n",
    "This is an example of the positive part atom combined with a smooth\n",
    "quadratic penalty. Above, the $x_i$ are rows of a matrix of\n",
    "features and the $y_i$ are labels coded as $\\pm 1$.\n",
    "\n",
    "Let’s generate some data appropriate for this problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    ">>>\n",
    "np.random.seed(400) # for reproducibility\n",
    "N = 500\n",
    "P = 2\n",
    ">>>\n",
    "Y = 2 * np.random.binomial(1, 0.5, size=(N,)) - 1.\n",
    "X = np.random.standard_normal((N,P))\n",
    "X[Y==1] += np.array([3,-2])[np.newaxis,:]\n",
    "X -= X.mean(0)[np.newaxis,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.5 0.5]] [[-0.25  0.25]] [0 2]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "clf = SVC(kernel='linear')\n",
    "X = np.array([[-1, -1], [-2, -1], [1, 1], [2, 1]])\n",
    "y = np.array([1, 1, 2, 2])\n",
    "clf.fit(X, y)\n",
    "print(clf.coef_, clf.dual_coef_, clf.support_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The hinge loss is not smooth, but it can be written as the composition\n",
    "of an `atom` (`positive_part`) with an affine transform determined\n",
    "by the data.\n",
    "\n",
    "Such objective functions can be smoothed. [NESTA](TODO) and\n",
    "[TFOCS](TODO) describe schemes in which smoothing of these atoms can\n",
    "be used to produce optimization problems with smooth objectives which\n",
    "can have additional structure imposed through optimization.\n",
    "\n",
    "Let us try smoothing the objective and using NESTA by smoothing the\n",
    "hinge loss. Of course, one can also solve the usual SVC dual problem by\n",
    "smoothing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.54059898, 0.44468378]),\n",
       " array([0.23285573, 0.        , 0.23285573, 0.        ]))"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def nesta_svm(X, y_pm, C=1.):\n",
    "    n, p = X.shape\n",
    "    X_1 = np.hstack([X, np.ones((X.shape[0], 1))])\n",
    "    hinge_loss = rr.positive_part.affine(-y_pm[:,None] * X_1, + np.ones(n),\n",
    "                                        lagrange=C)\n",
    "    selector = np.identity(p+1)[:p]\n",
    "    smooth_ = rr.quadratic_loss.linear(selector)\n",
    "    soln = rr.nesta(smooth_, None, hinge_loss)\n",
    "    return soln[0][:-1], soln[1]\n",
    "\n",
    "nesta_svm(X, 2 * (y - 1.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s try a little larger data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.03392693, -0.91351163, -0.0260219 , -0.29037068, -0.34668033,\n",
       "        -0.48974048, -0.34711183,  0.71658591,  0.05415365, -0.23807212,\n",
       "        -0.57111301, -0.21825985, -0.1718904 ,  0.34680402,  0.23467808,\n",
       "         0.17192434, -0.01959738,  0.15147373,  0.07052722,  0.11660805]])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_l = np.random.standard_normal((100, 20))\n",
    "Y_l = 2 * np.random.binomial(1, 0.5, (100,)) - 1\n",
    "C = 4.\n",
    "clf = SVC(kernel='linear', C=C)\n",
    "clf.fit(X_l, Y_l)\n",
    "clf.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1247f1a58>]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "solnR_ = nesta_svm(X_l, Y_l, C=C)[0]\n",
    "plt.scatter(clf.coef_, solnR_)\n",
    "plt.plot([-1,1], [-1,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using `regreg`, we can easily add penalty or constraint to the SVM\n",
    "objective."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.        , -0.20155192,  0.        ,  0.        ,  0.        ,\n",
       "       -0.03334131, -0.14715379,  0.17509434, -0.        , -0.        ,\n",
       "       -0.13078627,  0.        ,  0.        ,  0.02394207,  0.0756029 ,\n",
       "        0.01252739, -0.        , -0.        , -0.        , -0.        ])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def nesta_svm_pen(X, y_pm, atom, C=1.):\n",
    "    n, p = X.shape\n",
    "    X_1 = np.hstack([X, np.ones((X.shape[0], 1))])\n",
    "    hinge_loss = rr.positive_part.affine(-y_pm[:,None] * X_1, + np.ones(n),\n",
    "                                        lagrange=C)\n",
    "    selector = np.identity(p+1)[:p]\n",
    "    smooth_ = rr.quadratic_loss.linear(selector)\n",
    "    atom_sep = rr.separable((p+1,), [atom], [slice(0,p)])\n",
    "    soln = rr.nesta(smooth_, atom_sep, hinge_loss)\n",
    "    return soln[0][:-1]\n",
    "\n",
    "bound = rr.l1norm(20, bound=0.8)\n",
    "nesta_svm_pen(X_l, Y_l, bound)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sparse Huberized SVM\n",
    "\n",
    "Instead of using NESTA we can just smooth the SVM with a fixed smoothing\n",
    "parameter and solve the problem directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x1249b2278>"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from regreg.smooth.losses import huberized_svm\n",
    "X_l_inter = np.hstack([X_l, np.ones((X_l.shape[0],1))])\n",
    "huber_svm = huberized_svm(X_l_inter, Y_l, smoothing_parameter=0.001, coef=C)\n",
    "coef_h = huber_svm.solve(min_its=100)[:-1]\n",
    "plt.scatter(coef_h, clf.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding penalties or constraints is again straightforward."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "penalty = rr.l1norm(X_l.shape[1], lagrange=8.)\n",
    "penalty_sep = rr.separable((X_l.shape[1]+1,), [penalty], [slice(0,X_l.shape[1])])\n",
    "huberized_problem = rr.simple_problem(huber_svm, penalty_sep)\n",
    "huberized_problem.solve()\n",
    "numpy2ri.deactivate()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}